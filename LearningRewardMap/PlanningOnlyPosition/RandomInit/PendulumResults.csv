numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	50	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward input	[[[-0.25      ]   [-0.24499999]   [-0.23999999]   [-0.235     ]   [-0.22999999]   [-0.22499999]   [-0.22      ]   [-0.21499999]   [-0.20999999]   [-0.205     ]   [-0.19999999]   [-0.19499999]   [-0.19      ]   [-0.185     ]   [-0.17999999]   [-0.175     ]   [-0.17      ]   [-0.16499999]   [-0.16      ]   [-0.155     ]   [-0.14999999]   [-0.145     ]   [-0.14      ]   [-0.13499999]   [-0.13      ]   [-0.125     ]   [-0.12      ]   [-0.11499999]   [-0.11      ]   [-0.105     ]   [-0.09999999]   [-0.095     ]   [-0.09      ]   [-0.085     ]   [-0.08      ]   [-0.075     ]   [-0.07      ]   [-0.065     ]   [-0.06      ]   [-0.055     ]   [-0.05      ]   [-0.045     ]   [-0.04      ]   [-0.035     ]   [-0.03      ]   [-0.025     ]   [-0.02      ]   [-0.015     ]   [-0.01      ]   [-0.005     ]   [-0.        ]   [-0.005     ]   [-0.01      ]   [-0.015     ]   [-0.02      ]   [-0.025     ]   [-0.03      ]   [-0.035     ]   [-0.04      ]   [-0.045     ]   [-0.05      ]   [-0.055     ]   [-0.06      ]   [-0.065     ]   [-0.07      ]   [-0.075     ]   [-0.08      ]   [-0.085     ]   [-0.09      ]   [-0.095     ]   [-0.09999999]   [-0.105     ]   [-0.11      ]   [-0.11499999]   [-0.12      ]   [-0.125     ]   [-0.13      ]   [-0.13499999]   [-0.14      ]   [-0.145     ]   [-0.14999999]   [-0.155     ]   [-0.16      ]   [-0.16499999]   [-0.17      ]   [-0.175     ]   [-0.17999999]   [-0.185     ]   [-0.19      ]   [-0.19499999]   [-0.19999999]   [-0.205     ]   [-0.20999999]   [-0.21499999]   [-0.22      ]   [-0.22499999]   [-0.22999999]   [-0.235     ]   [-0.23999999]   [-0.24499999]   [-0.25      ]   [-0.255     ]   [-0.25999999]   [-0.26499999]   [-0.26999998]   [-0.27500001]   [-0.28      ]   [-0.285     ]   [-0.28999999]   [-0.29499999]   [-0.29999998]   [-0.30500001]   [-0.31      ]   [-0.315     ]   [-0.31999999]   [-0.32499999]   [-0.32999998]   [-0.33499998]   [-0.34      ]   [-0.345     ]   [-0.34999999]   [-0.35499999]   [-0.35999998]   [-0.36499998]   [-0.37      ]   [-0.375     ]   [-0.38      ]   [-0.38499999]   [-0.38999999]   [-0.39499998]   [-0.39999998]   [-0.405     ]   [-0.41      ]   [-0.41499999]   [-0.41999999]   [-0.42499998]   [-0.42999998]   [-0.435     ]   [-0.44      ]   [-0.44499999]   [-0.44999999]   [-0.45499998]   [-0.45999998]   [-0.465     ]   [-0.47      ]   [-0.47499999]   [-0.47999999]   [-0.48499998]   [-0.48999998]   [-0.49499997]   [-0.5       ]   [-0.49499997]   [-0.48999998]   [-0.48499998]   [-0.47999999]   [-0.47499999]   [-0.47      ]   [-0.465     ]   [-0.45999998]   [-0.45499998]   [-0.44999999]   [-0.44499999]   [-0.44      ]   [-0.435     ]   [-0.42999998]   [-0.42499998]   [-0.41999999]   [-0.41499999]   [-0.41      ]   [-0.405     ]   [-0.39999998]   [-0.39499998]   [-0.38999999]   [-0.38499999]   [-0.38      ]   [-0.375     ]   [-0.37      ]   [-0.36499998]   [-0.35999998]   [-0.35499999]   [-0.34999999]   [-0.345     ]   [-0.34      ]   [-0.33499998]   [-0.32999998]   [-0.32499999]   [-0.31999999]   [-0.315     ]   [-0.31      ]   [-0.30500001]   [-0.29999998]   [-0.29499999]   [-0.28999999]   [-0.285     ]   [-0.28      ]   [-0.27500001]   [-0.26999998]   [-0.26499999]   [-0.25999999]   [-0.255     ]]] 	
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1226.62988829	
300	-1319.23562702	
400	-1306.33686122	
500	-1211.88776861	
600	-1261.28768946	
700	-1223.9611307	
800	-1458.43240086	
900	-1232.46957222	
Time Training (1000episodes)	6604.3693237305	
Evaluation Episode	 Reward 	
0	-1264.79551422	
1	-848.988662957	
2	-1319.68053494	
3	-1270.23066826	
4	-1299.92288121	
5	-1349.96935788	
6	-1266.32036117	
7	-1478.41184475	
8	-1370.14557586	
9	-1415.04169426	
10	-1451.40399443	
11	-1373.52200123	
12	-1348.62316039	
13	-1363.70258428	
14	-1197.7466123	
15	-1373.0992239	
16	-1374.88312228	
17	-1057.25563952	
18	-1343.50477186	
19	-1377.52535489	
20	-1312.33345992	
21	-1360.2088124	
22	-949.437952986	
23	-1679.50593018	
24	-1395.13789856	
25	-930.703648655	
26	-1732.67657013	
27	-1344.14589316	
28	-1071.77877286	
29	-1164.87811872	
30	-718.326105515	
31	-1669.61732997	
32	-1444.96364495	
33	-1375.73390765	
34	-1515.77234241	
35	-1729.44405693	
36	-1355.98050409	
37	-949.284554007	
38	-1057.01186517	
39	-1357.26368362	
40	-1249.46158582	
41	-1351.92967571	
42	-1373.20723831	
43	-1717.96014657	
44	-1523.05553257	
45	-1346.8019309	
46	-1399.21479253	
47	-1508.01593886	
48	-1035.27086621	
49	-1667.82330372	
50	-944.073397324	
51	-1341.42913397	
52	-1306.27731116	
53	-1573.96115107	
54	-1061.208819	
55	-1331.45780732	
56	-1725.22866705	
57	-1366.09939445	
58	-1732.57283831	
59	-1474.60330678	
60	-1161.28903348	
61	-1730.92313189	
62	-1169.57919794	
63	-1072.66131903	
64	-1352.50194923	
65	-1576.92910562	
66	-1382.85152904	
67	-1679.19309353	
68	-1351.82504964	
69	-1352.41413193	
70	-1354.53907118	
71	-1485.63823817	
72	-1371.20854833	
73	-1566.86720246	
74	-1739.62294341	
75	-918.692698334	
76	-1345.85376089	
77	-901.520430801	
78	-1285.20094654	
79	-1432.08727836	
80	-1264.47787739	
81	-1732.35483629	
82	-1134.21483881	
83	-1282.24555561	
84	-1340.84188845	
85	-1059.76963492	
86	-949.115587455	
87	-1368.17129232	
88	-782.609323622	
89	-1443.68388325	
90	-1340.17904579	
91	-1361.33584362	
92	-1359.38068396	
93	-1729.45862962	
94	-1384.62452054	
95	-1733.69479523	
96	-1362.28121307	
97	-1610.1861563	
98	-1318.21980159	
99	-1361.50472415	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward input	[[[-0.25      ]   [-0.24499999]   [-0.23999999]   [-0.235     ]   [-0.22999999]   [-0.22499999]   [-0.22      ]   [-0.21499999]   [-0.20999999]   [-0.205     ]   [-0.19999999]   [-0.19499999]   [-0.19      ]   [-0.185     ]   [-0.17999999]   [-0.175     ]   [-0.17      ]   [-0.16499999]   [-0.16      ]   [-0.155     ]   [-0.14999999]   [-0.145     ]   [-0.14      ]   [-0.13499999]   [-0.13      ]   [-0.125     ]   [-0.12      ]   [-0.11499999]   [-0.11      ]   [-0.105     ]   [-0.09999999]   [-0.095     ]   [-0.09      ]   [-0.085     ]   [-0.08      ]   [-0.075     ]   [-0.07      ]   [-0.065     ]   [-0.06      ]   [-0.055     ]   [-0.05      ]   [-0.045     ]   [-0.04      ]   [-0.035     ]   [-0.03      ]   [-0.025     ]   [-0.02      ]   [-0.015     ]   [-0.01      ]   [-0.005     ]   [-0.        ]   [-0.005     ]   [-0.01      ]   [-0.015     ]   [-0.02      ]   [-0.025     ]   [-0.03      ]   [-0.035     ]   [-0.04      ]   [-0.045     ]   [-0.05      ]   [-0.055     ]   [-0.06      ]   [-0.065     ]   [-0.07      ]   [-0.075     ]   [-0.08      ]   [-0.085     ]   [-0.09      ]   [-0.095     ]   [-0.09999999]   [-0.105     ]   [-0.11      ]   [-0.11499999]   [-0.12      ]   [-0.125     ]   [-0.13      ]   [-0.13499999]   [-0.14      ]   [-0.145     ]   [-0.14999999]   [-0.155     ]   [-0.16      ]   [-0.16499999]   [-0.17      ]   [-0.175     ]   [-0.17999999]   [-0.185     ]   [-0.19      ]   [-0.19499999]   [-0.19999999]   [-0.205     ]   [-0.20999999]   [-0.21499999]   [-0.22      ]   [-0.22499999]   [-0.22999999]   [-0.235     ]   [-0.23999999]   [-0.24499999]   [-0.25      ]   [-0.255     ]   [-0.25999999]   [-0.26499999]   [-0.26999998]   [-0.27500001]   [-0.28      ]   [-0.285     ]   [-0.28999999]   [-0.29499999]   [-0.29999998]   [-0.30500001]   [-0.31      ]   [-0.315     ]   [-0.31999999]   [-0.32499999]   [-0.32999998]   [-0.33499998]   [-0.34      ]   [-0.345     ]   [-0.34999999]   [-0.35499999]   [-0.35999998]   [-0.36499998]   [-0.37      ]   [-0.375     ]   [-0.38      ]   [-0.38499999]   [-0.38999999]   [-0.39499998]   [-0.39999998]   [-0.405     ]   [-0.41      ]   [-0.41499999]   [-0.41999999]   [-0.42499998]   [-0.42999998]   [-0.435     ]   [-0.44      ]   [-0.44499999]   [-0.44999999]   [-0.45499998]   [-0.45999998]   [-0.465     ]   [-0.47      ]   [-0.47499999]   [-0.47999999]   [-0.48499998]   [-0.48999998]   [-0.49499997]   [-0.5       ]   [-0.49499997]   [-0.48999998]   [-0.48499998]   [-0.47999999]   [-0.47499999]   [-0.47      ]   [-0.465     ]   [-0.45999998]   [-0.45499998]   [-0.44999999]   [-0.44499999]   [-0.44      ]   [-0.435     ]   [-0.42999998]   [-0.42499998]   [-0.41999999]   [-0.41499999]   [-0.41      ]   [-0.405     ]   [-0.39999998]   [-0.39499998]   [-0.38999999]   [-0.38499999]   [-0.38      ]   [-0.375     ]   [-0.37      ]   [-0.36499998]   [-0.35999998]   [-0.35499999]   [-0.34999999]   [-0.345     ]   [-0.34      ]   [-0.33499998]   [-0.32999998]   [-0.32499999]   [-0.31999999]   [-0.315     ]   [-0.31      ]   [-0.30500001]   [-0.29999998]   [-0.29499999]   [-0.28999999]   [-0.285     ]   [-0.28      ]   [-0.27500001]   [-0.26999998]   [-0.26499999]   [-0.25999999]   [-0.255     ]]] 	
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1301.94176593	
300	-1347.58888131	
400	-990.251938489	
500	-845.893757382	
600	-706.292807663	
700	-354.815665639	
800	-146.037227798	
900	-383.866918391	
Time Training (1000episodes)	5896.0803160668	
Evaluation Episode	 Reward 	
0	-120.50608808	
1	-120.808495445	
2	-119.277046701	
3	-478.714319479	
4	-594.882914272	
5	-124.440920742	
6	-351.610010401	
7	-243.584424675	
8	-351.089659739	
9	-837.44394554	
10	-236.566084087	
11	-123.805498172	
12	-360.183326321	
13	-244.754564135	
14	-123.476009391	
15	-126.09640441	
16	-353.834968425	
17	-595.148244306	
18	-488.335864428	
19	-124.798259213	
20	-360.435615676	
21	-625.212817059	
22	-475.016184717	
23	-243.284168728	
24	-350.972204915	
25	-460.501690084	
26	-476.191808215	
27	-700.871878958	
28	-749.833520972	
29	-752.633309613	
30	-124.231683847	
31	-356.477028648	
32	-362.125624785	
33	-124.932591908	
34	-359.808867196	
35	-354.196234114	
36	-476.965836791	
37	-124.284411219	
38	-229.298454792	
39	-121.285263029	
40	-123.602706528	
41	-124.72384414	
42	-125.40448726	
43	-739.159721172	
44	-362.193737831	
45	-357.042321262	
46	-469.992968592	
47	-759.732553733	
48	-481.660630464	
49	-122.913961234	
50	-620.614806642	
51	-237.982280195	
52	-122.212285701	
53	-123.792678907	
54	-483.600665073	
55	-125.334782105	
56	-484.97434032	
57	-122.254797726	
58	-358.739607016	
59	-120.3170812	
60	-602.7487712	
61	-0.6676944791	
62	-605.580453135	
63	-0.568431017	
64	-125.283026015	
65	-237.993644624	
66	-587.972108413	
67	-476.149431916	
68	-231.497107962	
69	-601.383362612	
70	-123.507598432	
71	-125.177263645	
72	-748.418638936	
73	-468.72407265	
74	-355.404368855	
75	-625.151748892	
76	-124.023063525	
77	-249.37934492	
78	-589.852717371	
79	-490.547899183	
80	-124.535184428	
81	-482.15712428	
82	-125.158524407	
83	-121.171654848	
84	-124.102467412	
85	-241.811675059	
86	-244.039247979	
87	-358.493000052	
88	-123.131426323	
89	-596.642885837	
90	-587.824229129	
91	-476.063322371	
92	-237.039540244	
93	-626.311020838	
94	-124.591163059	
95	-355.729500812	
96	-456.952767089	
97	-687.109577019	
98	-0.5587118879	
99	-233.081297372	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	10	
 learning rate	0.0001	
	 TAU	0.001
	 batch size	64
 reward input	[[[-0.25      ]   [-0.24499999]   [-0.23999999]   [-0.235     ]   [-0.22999999]   [-0.22499999]   [-0.22      ]   [-0.21499999]   [-0.20999999]   [-0.205     ]   [-0.19999999]   [-0.19499999]   [-0.19      ]   [-0.185     ]   [-0.17999999]   [-0.175     ]   [-0.17      ]   [-0.16499999]   [-0.16      ]   [-0.155     ]   [-0.14999999]   [-0.145     ]   [-0.14      ]   [-0.13499999]   [-0.13      ]   [-0.125     ]   [-0.12      ]   [-0.11499999]   [-0.11      ]   [-0.105     ]   [-0.09999999]   [-0.095     ]   [-0.09      ]   [-0.085     ]   [-0.08      ]   [-0.075     ]   [-0.07      ]   [-0.065     ]   [-0.06      ]   [-0.055     ]   [-0.05      ]   [-0.045     ]   [-0.04      ]   [-0.035     ]   [-0.03      ]   [-0.025     ]   [-0.02      ]   [-0.015     ]   [-0.01      ]   [-0.005     ]   [-0.        ]   [-0.005     ]   [-0.01      ]   [-0.015     ]   [-0.02      ]   [-0.025     ]   [-0.03      ]   [-0.035     ]   [-0.04      ]   [-0.045     ]   [-0.05      ]   [-0.055     ]   [-0.06      ]   [-0.065     ]   [-0.07      ]   [-0.075     ]   [-0.08      ]   [-0.085     ]   [-0.09      ]   [-0.095     ]   [-0.09999999]   [-0.105     ]   [-0.11      ]   [-0.11499999]   [-0.12      ]   [-0.125     ]   [-0.13      ]   [-0.13499999]   [-0.14      ]   [-0.145     ]   [-0.14999999]   [-0.155     ]   [-0.16      ]   [-0.16499999]   [-0.17      ]   [-0.175     ]   [-0.17999999]   [-0.185     ]   [-0.19      ]   [-0.19499999]   [-0.19999999]   [-0.205     ]   [-0.20999999]   [-0.21499999]   [-0.22      ]   [-0.22499999]   [-0.22999999]   [-0.235     ]   [-0.23999999]   [-0.24499999]   [-0.25      ]   [-0.255     ]   [-0.25999999]   [-0.26499999]   [-0.26999998]   [-0.27500001]   [-0.28      ]   [-0.285     ]   [-0.28999999]   [-0.29499999]   [-0.29999998]   [-0.30500001]   [-0.31      ]   [-0.315     ]   [-0.31999999]   [-0.32499999]   [-0.32999998]   [-0.33499998]   [-0.34      ]   [-0.345     ]   [-0.34999999]   [-0.35499999]   [-0.35999998]   [-0.36499998]   [-0.37      ]   [-0.375     ]   [-0.38      ]   [-0.38499999]   [-0.38999999]   [-0.39499998]   [-0.39999998]   [-0.405     ]   [-0.41      ]   [-0.41499999]   [-0.41999999]   [-0.42499998]   [-0.42999998]   [-0.435     ]   [-0.44      ]   [-0.44499999]   [-0.44999999]   [-0.45499998]   [-0.45999998]   [-0.465     ]   [-0.47      ]   [-0.47499999]   [-0.47999999]   [-0.48499998]   [-0.48999998]   [-0.49499997]   [-0.5       ]   [-0.49499997]   [-0.48999998]   [-0.48499998]   [-0.47999999]   [-0.47499999]   [-0.47      ]   [-0.465     ]   [-0.45999998]   [-0.45499998]   [-0.44999999]   [-0.44499999]   [-0.44      ]   [-0.435     ]   [-0.42999998]   [-0.42499998]   [-0.41999999]   [-0.41499999]   [-0.41      ]   [-0.405     ]   [-0.39999998]   [-0.39499998]   [-0.38999999]   [-0.38499999]   [-0.38      ]   [-0.375     ]   [-0.37      ]   [-0.36499998]   [-0.35999998]   [-0.35499999]   [-0.34999999]   [-0.345     ]   [-0.34      ]   [-0.33499998]   [-0.32999998]   [-0.32499999]   [-0.31999999]   [-0.315     ]   [-0.31      ]   [-0.30500001]   [-0.29999998]   [-0.29499999]   [-0.28999999]   [-0.285     ]   [-0.28      ]   [-0.27500001]   [-0.26999998]   [-0.26499999]   [-0.25999999]   [-0.255     ]]] 	
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1258.17392535	
300	-1278.99723792	
400	-1007.40665767	
500	-610.066767948	
600	-519.808517507	
700	-388.120817547	
800	-291.960665903	
900	-255.932287492	
Time Training (1000episodes)	5914.4075160027	
Evaluation Episode	 Reward 	
0	-253.780223053	
1	-251.574471753	
2	-123.523014932	
3	-471.776386395	
4	-125.038339958	
5	-717.57216517	
6	-245.711032133	
7	-469.029627309	
8	-882.008648055	
9	-494.257390246	
10	-651.176702609	
11	-125.010596761	
12	-125.050243652	
13	-0.3318099288	
14	-250.805598069	
15	-471.535610928	
16	-124.836738451	
17	-683.933289225	
18	-235.749345394	
19	-242.325751157	
20	-363.67444366	
21	-126.507842104	
22	-125.420616548	
23	-125.098993056	
24	-0.1225162783	
25	-468.937975297	
26	-243.735165705	
27	-238.459114855	
28	-125.752861698	
29	-368.170463467	
30	-241.128454598	
31	-243.455075923	
32	-746.905124867	
33	-524.497155834	
34	-240.768468791	
35	-495.700109261	
36	-473.892643374	
37	-371.982800929	
38	-355.901592429	
39	-376.995598112	
40	-501.531148628	
41	-245.792794709	
42	-125.353164536	
43	-125.122999567	
44	-124.820713473	
45	-359.467515701	
46	-124.73370331	
47	-355.475716049	
48	-473.484689728	
49	-124.147620224	
50	-247.628794796	
51	-120.357403903	
52	-238.85269334	
53	-125.48974986	
54	-0.254415226	
55	-249.371022952	
56	-578.863788087	
57	-355.544190634	
58	-125.616354899	
59	-354.535544301	
60	-363.519545638	
61	-125.671071073	
62	-365.846407708	
63	-357.288819642	
64	-364.10102538	
65	-474.285123979	
66	-248.812771517	
67	-354.592284278	
68	-498.339738888	
69	-251.460564622	
70	-476.071158719	
71	-125.760916832	
72	-493.345206361	
73	-125.260785819	
74	-245.434673692	
75	-126.647156599	
76	-605.932533785	
77	-121.834708901	
78	-123.744554963	
79	-234.058992333	
80	-123.429986981	
81	-123.079095423	
82	-125.090964259	
83	-361.676325953	
84	-247.8947739	
85	-0.4892720773	
86	-366.130055532	
87	-349.546660538	
88	-614.082520857	
89	-119.409949089	
90	-126.568328681	
91	-632.504805519	
92	-605.732473516	
93	-606.127013128	
94	-241.452900181	
95	-246.80130915	
96	-485.831636444	
97	-370.667714445	
98	-126.787143751	
99	-125.136773812	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	-1	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward input	[[[-0.25      ]   [-0.24499999]   [-0.23999999]   [-0.235     ]   [-0.22999999]   [-0.22499999]   [-0.22      ]   [-0.21499999]   [-0.20999999]   [-0.205     ]   [-0.19999999]   [-0.19499999]   [-0.19      ]   [-0.185     ]   [-0.17999999]   [-0.175     ]   [-0.17      ]   [-0.16499999]   [-0.16      ]   [-0.155     ]   [-0.14999999]   [-0.145     ]   [-0.14      ]   [-0.13499999]   [-0.13      ]   [-0.125     ]   [-0.12      ]   [-0.11499999]   [-0.11      ]   [-0.105     ]   [-0.09999999]   [-0.095     ]   [-0.09      ]   [-0.085     ]   [-0.08      ]   [-0.075     ]   [-0.07      ]   [-0.065     ]   [-0.06      ]   [-0.055     ]   [-0.05      ]   [-0.045     ]   [-0.04      ]   [-0.035     ]   [-0.03      ]   [-0.025     ]   [-0.02      ]   [-0.015     ]   [-0.01      ]   [-0.005     ]   [-0.        ]   [-0.005     ]   [-0.01      ]   [-0.015     ]   [-0.02      ]   [-0.025     ]   [-0.03      ]   [-0.035     ]   [-0.04      ]   [-0.045     ]   [-0.05      ]   [-0.055     ]   [-0.06      ]   [-0.065     ]   [-0.07      ]   [-0.075     ]   [-0.08      ]   [-0.085     ]   [-0.09      ]   [-0.095     ]   [-0.09999999]   [-0.105     ]   [-0.11      ]   [-0.11499999]   [-0.12      ]   [-0.125     ]   [-0.13      ]   [-0.13499999]   [-0.14      ]   [-0.145     ]   [-0.14999999]   [-0.155     ]   [-0.16      ]   [-0.16499999]   [-0.17      ]   [-0.175     ]   [-0.17999999]   [-0.185     ]   [-0.19      ]   [-0.19499999]   [-0.19999999]   [-0.205     ]   [-0.20999999]   [-0.21499999]   [-0.22      ]   [-0.22499999]   [-0.22999999]   [-0.235     ]   [-0.23999999]   [-0.24499999]   [-0.25      ]   [-0.255     ]   [-0.25999999]   [-0.26499999]   [-0.26999998]   [-0.27500001]   [-0.28      ]   [-0.285     ]   [-0.28999999]   [-0.29499999]   [-0.29999998]   [-0.30500001]   [-0.31      ]   [-0.315     ]   [-0.31999999]   [-0.32499999]   [-0.32999998]   [-0.33499998]   [-0.34      ]   [-0.345     ]   [-0.34999999]   [-0.35499999]   [-0.35999998]   [-0.36499998]   [-0.37      ]   [-0.375     ]   [-0.38      ]   [-0.38499999]   [-0.38999999]   [-0.39499998]   [-0.39999998]   [-0.405     ]   [-0.41      ]   [-0.41499999]   [-0.41999999]   [-0.42499998]   [-0.42999998]   [-0.435     ]   [-0.44      ]   [-0.44499999]   [-0.44999999]   [-0.45499998]   [-0.45999998]   [-0.465     ]   [-0.47      ]   [-0.47499999]   [-0.47999999]   [-0.48499998]   [-0.48999998]   [-0.49499997]   [-0.5       ]   [-0.49499997]   [-0.48999998]   [-0.48499998]   [-0.47999999]   [-0.47499999]   [-0.47      ]   [-0.465     ]   [-0.45999998]   [-0.45499998]   [-0.44999999]   [-0.44499999]   [-0.44      ]   [-0.435     ]   [-0.42999998]   [-0.42499998]   [-0.41999999]   [-0.41499999]   [-0.41      ]   [-0.405     ]   [-0.39999998]   [-0.39499998]   [-0.38999999]   [-0.38499999]   [-0.38      ]   [-0.375     ]   [-0.37      ]   [-0.36499998]   [-0.35999998]   [-0.35499999]   [-0.34999999]   [-0.345     ]   [-0.34      ]   [-0.33499998]   [-0.32999998]   [-0.32499999]   [-0.31999999]   [-0.315     ]   [-0.31      ]   [-0.30500001]   [-0.29999998]   [-0.29499999]   [-0.28999999]   [-0.285     ]   [-0.28      ]   [-0.27500001]   [-0.26999998]   [-0.26499999]   [-0.25999999]   [-0.255     ]]] 	
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1210.34479944	
300	-1229.82613234	
400	-1216.85964812	
500	-1207.06642617	
600	-1192.73027477	
700	-1204.70556266	
800	-1224.65697009	
900	-1227.4728981	
1000	-1229.05163861	
1100	-1248.28033434	
1200	-1395.88060848	
1300	-1311.07438606	
1400	-1128.53740132	
1500	-1184.31161433	
1600	-1258.0652371	
1700	-1217.41849796	
1800	-1317.13793971	
1900	-1300.86219156	
Time Training (2000episodes)	12102.4929206371	
Evaluation Episode	 Reward 	
0	-777.199262235	
1	-1335.219953	
2	-1664.16043398	
3	-1709.14603911	
4	-1336.51404892	
5	-1734.84573451	
6	-1738.36674703	
7	-1343.56071837	
8	-1196.53991409	
9	-1201.00780286	
10	-1296.32891135	
11	-1328.47624142	
12	-1323.77170059	
13	-1209.91641644	
14	-1233.01880545	
15	-1291.97833636	
16	-1729.82921248	
17	-1240.22628223	
18	-1634.84307411	
19	-1264.99077658	
20	-1731.27975335	
21	-1303.38659816	
22	-1740.16285011	
23	-1241.71590852	
24	-1638.43397745	
25	-1267.40569239	
26	-1735.15045196	
27	-912.946551667	
28	-1012.85507014	
29	-1154.84169879	
30	-1188.91395616	
31	-1195.38315737	
32	-1719.64748571	
33	-1292.9604866	
34	-1290.4277176	
35	-1280.57129903	
36	-1692.29534697	
37	-1288.8681374	
38	-1259.28265584	
39	-1279.92529552	
40	-1732.74524432	
41	-1673.54413881	
42	-1238.2588942	
43	-1250.81115002	
44	-1008.64202007	
45	-1211.89940153	
46	-1180.09965695	
47	-1662.12011518	
48	-1158.61335894	
49	-1270.38365217	
50	-1257.02205385	
51	-1706.05231773	
52	-1243.85186368	
53	-1282.70058216	
54	-1729.4994504	
55	-1293.5888071	
56	-1267.28948326	
57	-1731.68230937	
58	-1243.53664668	
59	-1148.7716421	
60	-1325.71082351	
61	-1678.95236588	
62	-1260.33031996	
63	-1270.28312665	
64	-1698.64776487	
65	-1240.40636549	
66	-1267.78853422	
67	-1194.16492631	
68	-1267.42252031	
69	-1001.83800361	
70	-1621.79632884	
71	-1729.41204749	
72	-1273.34514988	
73	-1220.91196369	
74	-1258.38166911	
75	-1263.8099043	
76	-1208.06959073	
77	-1268.13406914	
78	-1282.09508819	
79	-1561.67025451	
80	-1157.47430143	
81	-768.764020205	
82	-1669.15501273	
83	-1320.74133537	
84	-1178.57731598	
85	-1700.36056854	
86	-1205.75182797	
87	-1529.67861244	
88	-1631.02381766	
89	-1736.97875065	
90	-887.58608414	
91	-765.728398815	
92	-1221.62353842	
93	-1217.3461469	
94	-1189.4281038	
95	-1069.25272075	
96	-1337.91617348	
97	-1267.68662448	
98	-1600.4033232	
99	-1732.73816995	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	10	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward input	[[[-0.25      ]   [-0.24499999]   [-0.23999999]   [-0.235     ]   [-0.22999999]   [-0.22499999]   [-0.22      ]   [-0.21499999]   [-0.20999999]   [-0.205     ]   [-0.19999999]   [-0.19499999]   [-0.19      ]   [-0.185     ]   [-0.17999999]   [-0.175     ]   [-0.17      ]   [-0.16499999]   [-0.16      ]   [-0.155     ]   [-0.14999999]   [-0.145     ]   [-0.14      ]   [-0.13499999]   [-0.13      ]   [-0.125     ]   [-0.12      ]   [-0.11499999]   [-0.11      ]   [-0.105     ]   [-0.09999999]   [-0.095     ]   [-0.09      ]   [-0.085     ]   [-0.08      ]   [-0.075     ]   [-0.07      ]   [-0.065     ]   [-0.06      ]   [-0.055     ]   [-0.05      ]   [-0.045     ]   [-0.04      ]   [-0.035     ]   [-0.03      ]   [-0.025     ]   [-0.02      ]   [-0.015     ]   [-0.01      ]   [-0.005     ]   [-0.        ]   [-0.005     ]   [-0.01      ]   [-0.015     ]   [-0.02      ]   [-0.025     ]   [-0.03      ]   [-0.035     ]   [-0.04      ]   [-0.045     ]   [-0.05      ]   [-0.055     ]   [-0.06      ]   [-0.065     ]   [-0.07      ]   [-0.075     ]   [-0.08      ]   [-0.085     ]   [-0.09      ]   [-0.095     ]   [-0.09999999]   [-0.105     ]   [-0.11      ]   [-0.11499999]   [-0.12      ]   [-0.125     ]   [-0.13      ]   [-0.13499999]   [-0.14      ]   [-0.145     ]   [-0.14999999]   [-0.155     ]   [-0.16      ]   [-0.16499999]   [-0.17      ]   [-0.175     ]   [-0.17999999]   [-0.185     ]   [-0.19      ]   [-0.19499999]   [-0.19999999]   [-0.205     ]   [-0.20999999]   [-0.21499999]   [-0.22      ]   [-0.22499999]   [-0.22999999]   [-0.235     ]   [-0.23999999]   [-0.24499999]   [-0.25      ]   [-0.255     ]   [-0.25999999]   [-0.26499999]   [-0.26999998]   [-0.27500001]   [-0.28      ]   [-0.285     ]   [-0.28999999]   [-0.29499999]   [-0.29999998]   [-0.30500001]   [-0.31      ]   [-0.315     ]   [-0.31999999]   [-0.32499999]   [-0.32999998]   [-0.33499998]   [-0.34      ]   [-0.345     ]   [-0.34999999]   [-0.35499999]   [-0.35999998]   [-0.36499998]   [-0.37      ]   [-0.375     ]   [-0.38      ]   [-0.38499999]   [-0.38999999]   [-0.39499998]   [-0.39999998]   [-0.405     ]   [-0.41      ]   [-0.41499999]   [-0.41999999]   [-0.42499998]   [-0.42999998]   [-0.435     ]   [-0.44      ]   [-0.44499999]   [-0.44999999]   [-0.45499998]   [-0.45999998]   [-0.465     ]   [-0.47      ]   [-0.47499999]   [-0.47999999]   [-0.48499998]   [-0.48999998]   [-0.49499997]   [-0.5       ]   [-0.49499997]   [-0.48999998]   [-0.48499998]   [-0.47999999]   [-0.47499999]   [-0.47      ]   [-0.465     ]   [-0.45999998]   [-0.45499998]   [-0.44999999]   [-0.44499999]   [-0.44      ]   [-0.435     ]   [-0.42999998]   [-0.42499998]   [-0.41999999]   [-0.41499999]   [-0.41      ]   [-0.405     ]   [-0.39999998]   [-0.39499998]   [-0.38999999]   [-0.38499999]   [-0.38      ]   [-0.375     ]   [-0.37      ]   [-0.36499998]   [-0.35999998]   [-0.35499999]   [-0.34999999]   [-0.345     ]   [-0.34      ]   [-0.33499998]   [-0.32999998]   [-0.32499999]   [-0.31999999]   [-0.315     ]   [-0.31      ]   [-0.30500001]   [-0.29999998]   [-0.29499999]   [-0.28999999]   [-0.285     ]   [-0.28      ]   [-0.27500001]   [-0.26999998]   [-0.26499999]   [-0.25999999]   [-0.255     ]]] 	
Episodes Spent Training	 10 Episode Eval Avg 	
200	-910.717407887	
300	-1065.4139398	
400	-1191.31066194	
500	-812.083375627	
600	-947.993651626	
700	-866.080694723	
800	-1109.84302646	
900	-1107.29582961	
1000	-920.536473665	
1100	-1092.87847402	
1200	-1174.00350834	
1300	-1052.19456657	
1400	-939.313980769	
1500	-1047.60166528	
		
*NOTE: above experiments had phase shift by PI/2		
		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	10	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward input	[[[ -0.        ]   [ -0.16      ]   [ -0.31999999]   [ -0.47999999]   [ -0.63999999]   [ -0.79999995]   [ -0.95999998]   [ -1.12      ]   [ -1.27999997]   [ -1.43999994]   [ -1.5999999 ]   [ -1.75999999]   [ -1.91999996]   [ -2.07999992]   [ -2.24000001]   [ -2.39999986]   [ -2.55999994]   [ -2.72000003]   [ -2.87999988]   [ -3.03999996]   [ -3.19999981]   [ -3.3599999 ]   [ -3.51999998]   [ -3.67999983]   [ -3.83999991]   [ -4.        ]   [ -4.15999985]   [ -4.31999969]   [ -4.48000002]   [ -4.63999987]   [ -4.79999971]   [ -4.96000004]   [ -5.11999989]   [ -5.27999973]   [ -5.44000006]   [ -5.5999999 ]   [ -5.75999975]   [ -5.92000008]   [ -6.07999992]   [ -6.23999977]   [ -6.39999962]   [ -6.55999994]   [ -6.71999979]   [ -6.87999964]   [ -7.03999996]   [ -7.19999981]   [ -7.35999966]   [ -7.51999998]   [ -7.67999983]   [ -7.83999968]   [ -8.        ]   [ -8.15999985]   [ -8.31999969]   [ -8.47999954]   [ -8.63999939]   [ -8.80000019]   [ -8.96000004]   [ -9.11999989]   [ -9.27999973]   [ -9.43999958]   [ -9.59999943]   [ -9.76000023]   [ -9.92000008]   [-10.07999992]   [-10.23999977]   [-10.39999962]   [-10.55999947]   [-10.71999931]   [-10.88000011]   [-11.03999996]   [-11.19999981]   [-11.35999966]   [-11.5199995 ]   [-11.67999935]   [-11.84000015]   [-12.        ]   [-12.15999985]   [-12.31999969]   [-12.47999954]   [-12.63999939]   [-12.79999924]   [-12.96000004]   [-13.11999989]   [-13.27999973]   [-13.43999958]   [-13.59999943]   [-13.75999928]   [-13.92000008]   [-14.07999992]   [-14.23999977]   [-14.39999962]   [-14.55999947]   [-14.71999931]   [-14.88000011]   [-15.03999996]   [-15.19999981]   [-15.35999966]   [-15.5199995 ]   [-15.67999935]   [-15.8399992 ]   [-15.8399992 ]   [-15.67999935]   [-15.5199995 ]   [-15.35999966]   [-15.19999981]   [-15.03999996]   [-14.88000011]   [-14.71999931]   [-14.55999947]   [-14.39999962]   [-14.23999977]   [-14.07999992]   [-13.92000008]   [-13.75999928]   [-13.59999943]   [-13.43999958]   [-13.27999973]   [-13.11999989]   [-12.96000004]   [-12.79999924]   [-12.63999939]   [-12.47999954]   [-12.31999969]   [-12.15999985]   [-12.        ]   [-11.84000015]   [-11.67999935]   [-11.5199995 ]   [-11.35999966]   [-11.19999981]   [-11.03999996]   [-10.88000011]   [-10.71999931]   [-10.55999947]   [-10.39999962]   [-10.23999977]   [-10.07999992]   [ -9.92000008]   [ -9.76000023]   [ -9.59999943]   [ -9.43999958]   [ -9.27999973]   [ -9.11999989]   [ -8.96000004]   [ -8.80000019]   [ -8.63999939]   [ -8.47999954]   [ -8.31999969]   [ -8.15999985]   [ -8.        ]   [ -7.83999968]   [ -7.67999983]   [ -7.51999998]   [ -7.35999966]   [ -7.19999981]   [ -7.03999996]   [ -6.87999964]   [ -6.71999979]   [ -6.55999994]   [ -6.39999962]   [ -6.23999977]   [ -6.07999992]   [ -5.92000008]   [ -5.75999975]   [ -5.5999999 ]   [ -5.44000006]   [ -5.27999973]   [ -5.11999989]   [ -4.96000004]   [ -4.79999971]   [ -4.63999987]   [ -4.48000002]   [ -4.31999969]   [ -4.15999985]   [ -4.        ]   [ -3.83999991]   [ -3.67999983]   [ -3.51999998]   [ -3.3599999 ]   [ -3.19999981]   [ -3.03999996]   [ -2.87999988]   [ -2.72000003]   [ -2.55999994]   [ -2.39999986]   [ -2.24000001]   [ -2.07999992]   [ -1.91999996]   [ -1.75999999]   [ -1.5999999 ]   [ -1.43999994]   [ -1.27999997]   [ -1.12      ]   [ -0.95999998]   [ -0.79999995]   [ -0.63999999]   [ -0.47999999]   [ -0.31999999]   [ -0.16      ]   [ -0.        ]]] 	
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1418.49567756	
300	-1144.38580992	
400	-1049.84842678	
500	-1285.64905931	
600	-1045.5499082	
700	-720.533108484	
800	-956.209808807	
900	-1135.21580996	
Time Training (1000episodes)	5503.5114810467	
Evaluation Episode	 Reward 	
0	-1664.06684724	
1	-126.011395594	
2	-122.422850477	
3	-0.1650254335	
4	-1676.25675806	
5	-1033.91165803	
6	-1644.86530223	
7	-1071.90303824	
8	-1186.36330005	
9	-1196.04921948	
10	-1178.74232586	
11	-1220.35029415	
12	-124.932936959	
13	-1525.09188774	
14	-1612.18192966	
15	-1250.38375967	
16	-1695.1037729	
17	-915.659213906	
18	-1372.41943958	
19	-122.137720109	
20	-124.275350171	
21	-1350.12266438	
22	-1686.47201072	
23	-980.738609464	
24	-1083.96425969	
25	-954.268173662	
26	-125.240508454	
27	-239.43591138	
28	-1349.0201386	
29	-1725.34728741	
30	-0.2088552869	
31	-125.527146539	
32	-1460.61826222	
33	-1734.08639968	
34	-1621.57239723	
35	-1566.49050549	
36	-1025.55985478	
37	-1704.39574084	
38	-948.631241399	
39	-119.520712104	
40	-123.261975976	
41	-119.515451919	
42	-124.314159353	
43	-126.098150124	
44	-125.823499355	
45	-1659.04284337	
46	-1566.41418668	
47	-836.183311297	
48	-124.725185403	
49	-0.0795261047	
50	-126.322391925	
51	-125.976832101	
52	-239.222024098	
53	-126.813131356	
54	-1526.7944932	
55	-1324.53630486	
56	-1696.53548368	
57	-0.3718907231	
58	-1645.21251544	
59	-942.860605407	
60	-126.339428102	
61	-1367.61083986	
62	-1052.87585333	
63	-119.180472233	
64	-1496.07157277	
65	-120.716890446	
66	-1665.88432868	
67	-1423.1705829	
68	-950.266392788	
69	-119.377038967	
70	-1136.57438349	
71	-1545.38044426	
72	-1055.44305579	
73	-1641.69462807	
74	-1190.05754068	
75	-1733.19652831	
76	-1055.41159539	
77	-120.766760924	
78	-1186.40409253	
79	-1274.76973301	
80	-1669.1344439	
81	-1507.93336068	
82	-1325.57738233	
83	-1647.08200622	
84	-1197.31505117	
85	-1479.89227562	
86	-1349.91973678	
87	-1078.74054799	
88	-120.158602833	
89	-1163.26841168	
90	-1257.67380705	
91	-1349.10341915	
92	-1164.06544684	
93	-1173.52346969	
94	-1462.77042126	
95	-1230.67775205	
96	-1255.58869009	
97	-1151.56760362	
98	-239.11580242	
99	-1294.95099698	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward input	[[[ -0.        ]   [ -0.16      ]   [ -0.31999999]   [ -0.47999999]   [ -0.63999999]   [ -0.79999995]   [ -0.95999998]   [ -1.12      ]   [ -1.27999997]   [ -1.43999994]   [ -1.5999999 ]   [ -1.75999999]   [ -1.91999996]   [ -2.07999992]   [ -2.24000001]   [ -2.39999986]   [ -2.55999994]   [ -2.72000003]   [ -2.87999988]   [ -3.03999996]   [ -3.19999981]   [ -3.3599999 ]   [ -3.51999998]   [ -3.67999983]   [ -3.83999991]   [ -4.        ]   [ -4.15999985]   [ -4.31999969]   [ -4.48000002]   [ -4.63999987]   [ -4.79999971]   [ -4.96000004]   [ -5.11999989]   [ -5.27999973]   [ -5.44000006]   [ -5.5999999 ]   [ -5.75999975]   [ -5.92000008]   [ -6.07999992]   [ -6.23999977]   [ -6.39999962]   [ -6.55999994]   [ -6.71999979]   [ -6.87999964]   [ -7.03999996]   [ -7.19999981]   [ -7.35999966]   [ -7.51999998]   [ -7.67999983]   [ -7.83999968]   [ -8.        ]   [ -8.15999985]   [ -8.31999969]   [ -8.47999954]   [ -8.63999939]   [ -8.80000019]   [ -8.96000004]   [ -9.11999989]   [ -9.27999973]   [ -9.43999958]   [ -9.59999943]   [ -9.76000023]   [ -9.92000008]   [-10.07999992]   [-10.23999977]   [-10.39999962]   [-10.55999947]   [-10.71999931]   [-10.88000011]   [-11.03999996]   [-11.19999981]   [-11.35999966]   [-11.5199995 ]   [-11.67999935]   [-11.84000015]   [-12.        ]   [-12.15999985]   [-12.31999969]   [-12.47999954]   [-12.63999939]   [-12.79999924]   [-12.96000004]   [-13.11999989]   [-13.27999973]   [-13.43999958]   [-13.59999943]   [-13.75999928]   [-13.92000008]   [-14.07999992]   [-14.23999977]   [-14.39999962]   [-14.55999947]   [-14.71999931]   [-14.88000011]   [-15.03999996]   [-15.19999981]   [-15.35999966]   [-15.5199995 ]   [-15.67999935]   [-15.8399992 ]   [-15.8399992 ]   [-15.67999935]   [-15.5199995 ]   [-15.35999966]   [-15.19999981]   [-15.03999996]   [-14.88000011]   [-14.71999931]   [-14.55999947]   [-14.39999962]   [-14.23999977]   [-14.07999992]   [-13.92000008]   [-13.75999928]   [-13.59999943]   [-13.43999958]   [-13.27999973]   [-13.11999989]   [-12.96000004]   [-12.79999924]   [-12.63999939]   [-12.47999954]   [-12.31999969]   [-12.15999985]   [-12.        ]   [-11.84000015]   [-11.67999935]   [-11.5199995 ]   [-11.35999966]   [-11.19999981]   [-11.03999996]   [-10.88000011]   [-10.71999931]   [-10.55999947]   [-10.39999962]   [-10.23999977]   [-10.07999992]   [ -9.92000008]   [ -9.76000023]   [ -9.59999943]   [ -9.43999958]   [ -9.27999973]   [ -9.11999989]   [ -8.96000004]   [ -8.80000019]   [ -8.63999939]   [ -8.47999954]   [ -8.31999969]   [ -8.15999985]   [ -8.        ]   [ -7.83999968]   [ -7.67999983]   [ -7.51999998]   [ -7.35999966]   [ -7.19999981]   [ -7.03999996]   [ -6.87999964]   [ -6.71999979]   [ -6.55999994]   [ -6.39999962]   [ -6.23999977]   [ -6.07999992]   [ -5.92000008]   [ -5.75999975]   [ -5.5999999 ]   [ -5.44000006]   [ -5.27999973]   [ -5.11999989]   [ -4.96000004]   [ -4.79999971]   [ -4.63999987]   [ -4.48000002]   [ -4.31999969]   [ -4.15999985]   [ -4.        ]   [ -3.83999991]   [ -3.67999983]   [ -3.51999998]   [ -3.3599999 ]   [ -3.19999981]   [ -3.03999996]   [ -2.87999988]   [ -2.72000003]   [ -2.55999994]   [ -2.39999986]   [ -2.24000001]   [ -2.07999992]   [ -1.91999996]   [ -1.75999999]   [ -1.5999999 ]   [ -1.43999994]   [ -1.27999997]   [ -1.12      ]   [ -0.95999998]   [ -0.79999995]   [ -0.63999999]   [ -0.47999999]   [ -0.31999999]   [ -0.16      ]   [ -0.        ]]] 	
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1087.1516019	
300	-1290.9819475	
400	-1318.40821288	
500	-1317.21082421	
600	-1280.50889383	
700	-1337.69360686	
800	-1231.03186295	
900	-1226.89597193	
Time Training (1000episodes)	5223.1289987564	
Evaluation Episode	 Reward 	
0	-989.243341372	
1	-1351.60728765	
2	-1291.72661718	
3	-1312.07872945	
4	-1355.27361489	
5	-1022.4044517	
6	-1357.80654509	
7	-1240.06373416	
8	-955.544281053	
9	-1337.39872886	
10	-1312.35873433	
11	-1315.33683194	
12	-1354.46313329	
13	-1332.26575657	
14	-1347.23642805	
15	-1317.01814407	
16	-1324.87655339	
17	-1331.45432721	
18	-1321.26951398	
19	-1282.84711853	
20	-1355.3991734	
21	-1175.50593738	
22	-1329.76786271	
23	-1315.02536135	
24	-1299.01471457	
25	-1332.79370753	
26	-1344.45566998	
27	-1281.43797119	
28	-1330.45953743	
29	-1355.20412354	
30	-1318.10652537	
31	-1235.13844749	
32	-917.0435687	
33	-1334.43447413	
34	-1245.66848217	
35	-1344.52223593	
36	-1355.46466387	
37	-926.356097287	
38	-1302.61189167	
39	-1298.40545819	
40	-1370.20853237	
41	-1339.83328133	
42	-1309.6626653	
43	-1317.72661459	
44	-1319.96632096	
45	-1335.01887157	
46	-915.678001028	
47	-910.249414238	
48	-911.116972817	
49	-956.224635875	
50	-1305.216944	
51	-1365.63692439	
52	-1341.56446094	
53	-1352.33179272	
54	-1346.67754425	
55	-1363.08881859	
56	-1357.10585971	
57	-1340.45152997	
58	-1190.2218453	
59	-1310.58875091	
60	-1316.72967274	
61	-1330.45808429	
62	-1313.04213594	
63	-1352.14197128	
64	-1354.61066581	
65	-1242.28175748	
66	-1263.93505281	
67	-1336.55582648	
68	-1322.38140119	
69	-1316.93935732	
70	-1354.57810392	
71	-1321.97381123	
72	-1307.89561259	
73	-1251.25056953	
74	-1362.06169793	
75	-922.30614072	
76	-1362.27667581	
77	-1357.01154801	
78	-1332.23308812	
79	-1331.74253375	
80	-1319.54150983	
81	-1318.31116982	
82	-1319.84571589	
83	-1314.2902328	
84	-1368.19457809	
85	-1334.88175224	
86	-1298.40628805	
87	-1331.75604383	
88	-1374.69033892	
89	-1310.378895	
90	-1729.62635679	
91	-1325.18428845	
92	-1368.76885836	
93	-1312.02386721	
94	-1364.13232491	
95	-913.118347431	
96	-983.147430844	
97	-1309.10079433	
98	-1314.46611725	
99	-1190.95369048	
endExperiment		
		
		
numstates	200	
 num value iterations	30	
 conv type	 regular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward input	[[[ -0.        ]   [ -0.16      ]   [ -0.31999999]   [ -0.47999999]   [ -0.63999999]   [ -0.79999995]   [ -0.95999998]   [ -1.12      ]   [ -1.27999997]   [ -1.43999994]   [ -1.5999999 ]   [ -1.75999999]   [ -1.91999996]   [ -2.07999992]   [ -2.24000001]   [ -2.39999986]   [ -2.55999994]   [ -2.72000003]   [ -2.87999988]   [ -3.03999996]   [ -3.19999981]   [ -3.3599999 ]   [ -3.51999998]   [ -3.67999983]   [ -3.83999991]   [ -4.        ]   [ -4.15999985]   [ -4.31999969]   [ -4.48000002]   [ -4.63999987]   [ -4.79999971]   [ -4.96000004]   [ -5.11999989]   [ -5.27999973]   [ -5.44000006]   [ -5.5999999 ]   [ -5.75999975]   [ -5.92000008]   [ -6.07999992]   [ -6.23999977]   [ -6.39999962]   [ -6.55999994]   [ -6.71999979]   [ -6.87999964]   [ -7.03999996]   [ -7.19999981]   [ -7.35999966]   [ -7.51999998]   [ -7.67999983]   [ -7.83999968]   [ -8.        ]   [ -8.15999985]   [ -8.31999969]   [ -8.47999954]   [ -8.63999939]   [ -8.80000019]   [ -8.96000004]   [ -9.11999989]   [ -9.27999973]   [ -9.43999958]   [ -9.59999943]   [ -9.76000023]   [ -9.92000008]   [-10.07999992]   [-10.23999977]   [-10.39999962]   [-10.55999947]   [-10.71999931]   [-10.88000011]   [-11.03999996]   [-11.19999981]   [-11.35999966]   [-11.5199995 ]   [-11.67999935]   [-11.84000015]   [-12.        ]   [-12.15999985]   [-12.31999969]   [-12.47999954]   [-12.63999939]   [-12.79999924]   [-12.96000004]   [-13.11999989]   [-13.27999973]   [-13.43999958]   [-13.59999943]   [-13.75999928]   [-13.92000008]   [-14.07999992]   [-14.23999977]   [-14.39999962]   [-14.55999947]   [-14.71999931]   [-14.88000011]   [-15.03999996]   [-15.19999981]   [-15.35999966]   [-15.5199995 ]   [-15.67999935]   [-15.8399992 ]   [-15.8399992 ]   [-15.67999935]   [-15.5199995 ]   [-15.35999966]   [-15.19999981]   [-15.03999996]   [-14.88000011]   [-14.71999931]   [-14.55999947]   [-14.39999962]   [-14.23999977]   [-14.07999992]   [-13.92000008]   [-13.75999928]   [-13.59999943]   [-13.43999958]   [-13.27999973]   [-13.11999989]   [-12.96000004]   [-12.79999924]   [-12.63999939]   [-12.47999954]   [-12.31999969]   [-12.15999985]   [-12.        ]   [-11.84000015]   [-11.67999935]   [-11.5199995 ]   [-11.35999966]   [-11.19999981]   [-11.03999996]   [-10.88000011]   [-10.71999931]   [-10.55999947]   [-10.39999962]   [-10.23999977]   [-10.07999992]   [ -9.92000008]   [ -9.76000023]   [ -9.59999943]   [ -9.43999958]   [ -9.27999973]   [ -9.11999989]   [ -8.96000004]   [ -8.80000019]   [ -8.63999939]   [ -8.47999954]   [ -8.31999969]   [ -8.15999985]   [ -8.        ]   [ -7.83999968]   [ -7.67999983]   [ -7.51999998]   [ -7.35999966]   [ -7.19999981]   [ -7.03999996]   [ -6.87999964]   [ -6.71999979]   [ -6.55999994]   [ -6.39999962]   [ -6.23999977]   [ -6.07999992]   [ -5.92000008]   [ -5.75999975]   [ -5.5999999 ]   [ -5.44000006]   [ -5.27999973]   [ -5.11999989]   [ -4.96000004]   [ -4.79999971]   [ -4.63999987]   [ -4.48000002]   [ -4.31999969]   [ -4.15999985]   [ -4.        ]   [ -3.83999991]   [ -3.67999983]   [ -3.51999998]   [ -3.3599999 ]   [ -3.19999981]   [ -3.03999996]   [ -2.87999988]   [ -2.72000003]   [ -2.55999994]   [ -2.39999986]   [ -2.24000001]   [ -2.07999992]   [ -1.91999996]   [ -1.75999999]   [ -1.5999999 ]   [ -1.43999994]   [ -1.27999997]   [ -1.12      ]   [ -0.95999998]   [ -0.79999995]   [ -0.63999999]   [ -0.47999999]   [ -0.31999999]   [ -0.16      ]   [ -0.        ]]] 	
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1200.61983774	
300	-1313.83140918	
400	-1284.73641867	
500	-1308.21987928	
600	-1323.09316085	
700	-1321.04608541	
800	-1132.7761222	
900	-1276.52981739	
Time Training (1000episodes)	5027.7036623955	
Evaluation Episode	 Reward 	
0	-1551.45969112	
1	-1723.89651956	
2	-1255.35121283	
3	-1706.3126849	
4	-1099.90517629	
5	-1155.81122597	
6	-1136.64595506	
7	-802.720008927	
8	-1163.76517866	
9	-1492.1112621	
10	-1354.87613983	
11	-1380.1289502	
12	-1020.84661818	
13	-1188.76427146	
14	-947.169737396	
15	-1339.23569914	
16	-1706.91816653	
17	-1235.67794167	
18	-1162.95653631	
19	-1350.57246868	
20	-1348.88290055	
21	-1313.56768778	
22	-1632.80635629	
23	-1556.27396006	
24	-1091.33875796	
25	-1174.23055276	
26	-1058.84165712	
27	-1040.92581002	
28	-1219.12077502	
29	-947.975933967	
30	-1519.45770492	
31	-1586.09526182	
32	-1282.75666004	
33	-1476.58875805	
34	-1119.36508347	
35	-1055.54104209	
36	-1340.583687	
37	-846.635520315	
38	-1495.0055234	
39	-1336.62809657	
40	-1308.40242344	
41	-1048.09300483	
42	-950.204088509	
43	-1217.88897541	
44	-1291.25831043	
45	-1107.19718671	
46	-1162.37803284	
47	-1414.47651277	
48	-1328.44058766	
49	-1179.56848227	
50	-1708.43222237	
51	-1699.81034293	
52	-1295.08613463	
53	-1314.75334205	
54	-1354.05191221	
55	-1029.99891923	
56	-1525.601079	
57	-1344.51284163	
58	-1198.1838999	
59	-1419.70065874	
60	-949.25388815	
61	-1161.44225306	
62	-1734.82796286	
63	-1346.47109385	
64	-1051.73637942	
65	-1348.57866472	
66	-1354.31987832	
67	-1575.33893197	
68	-1442.46811245	
69	-1470.44815208	
70	-1188.68189294	
71	-1087.86799744	
72	-1063.0554023	
73	-1520.94100109	
74	-1054.79908374	
75	-1350.10969982	
76	-1413.20257311	
77	-1389.18036607	
78	-1332.34238434	
79	-1690.07378005	
80	-1723.66497723	
81	-1345.55404953	
82	-1285.08514288	
83	-1031.58601758	
84	-1098.24237702	
85	-1345.1106527	
86	-718.564116972	
87	-1492.39054267	
88	-1283.86769348	
89	-1442.68060411	
90	-1667.41128252	
91	-1703.0319243	
92	-1348.86066823	
93	-1034.17271174	
94	-2.405062392	
95	-947.282196572	
96	-1282.32580291	
97	-1355.44030413	
98	-1165.79854025	
99	-1204.14200145	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 regular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward	 Param to be learned 	
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1117.09116392	
300	-1056.53051658	
400	-792.505159189	
500	-815.597150451	
600	-641.817142686	
700	-991.85001528	
800	-977.792752714	
900	-1085.78916162	
Time Training (1000episodes)	3702.7851231098	
Evaluation Episode	 Reward 	
0	-846.201597172	
1	-1600.72176935	
2	-0.3668874171	
3	-1078.31570028	
4	-1467.08527511	
5	-126.138852296	
6	-126.464351265	
7	-1735.93991182	
8	-1070.04841634	
9	-1733.17058531	
10	-1471.46625377	
11	-1536.83518303	
12	-1143.04938514	
13	-1715.40406766	
14	-1535.39778165	
15	-1481.00398767	
16	-1466.63404325	
17	-1485.26892075	
18	-626.847386257	
19	-1085.58677469	
20	-1324.86323002	
21	-124.944470654	
22	-127.140786413	
23	-948.794006761	
24	-124.880058012	
25	-1203.69703635	
26	-1069.89786886	
27	-1691.58207455	
28	-250.900591949	
29	-1464.24959529	
30	-993.908054262	
31	-498.710817116	
32	-1248.40266146	
33	-0.2182058033	
34	-1413.40963177	
35	-984.747799523	
36	-1368.52582658	
37	-1733.38602852	
38	-1721.64530803	
39	-1527.80547123	
40	-1254.05307078	
41	-1192.750213	
42	-126.930148124	
43	-250.303217776	
44	-127.099638524	
45	-1217.82552164	
46	-1400.74495946	
47	-1573.68718391	
48	-930.444816587	
49	-126.709321307	
50	-1733.36233429	
51	-895.787020082	
52	-1225.33996214	
53	-1457.05723792	
54	-1288.72462727	
55	-1444.11941556	
56	-126.542261459	
57	-124.320147698	
58	-957.421923821	
59	-1732.33739975	
60	-1499.5298545	
61	-1054.39632932	
62	-1151.945449	
63	-1609.63982473	
64	-1284.34068099	
65	-1246.8002917	
66	-1102.16983834	
67	-1446.28427201	
68	-124.811155722	
69	-1721.34556361	
70	-125.100089495	
71	-0.5286727176	
72	-125.565991141	
73	-1487.96843181	
74	-1424.22402683	
75	-125.286828851	
76	-1109.59137048	
77	-882.321085658	
78	-1393.15879919	
79	-1211.02391113	
80	-1326.0013045	
81	-1401.25342336	
82	-1729.58810311	
83	-1641.04892376	
84	-1239.41409877	
85	-987.514014981	
86	-1495.45820912	
87	-1379.24741176	
88	-125.635610234	
89	-1558.33977118	
90	-1711.29943079	
91	-987.632424368	
92	-1100.7363958	
93	-126.67054789	
94	-1607.76622911	
95	-1611.47247286	
96	-1118.61164623	
97	-991.010201878	
98	-1127.74451504	
99	-0.3924574081	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward	 Param to be learned 	
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1242.89531674	
300	-954.90507747	
400	-1063.45653885	
500	-1296.8777946	
600	-1099.20137722	
700	-977.199060738	
800	-1051.30723753	
900	-1091.88959494	
Time Training (1000episodes)	4829.4354732037	
Evaluation Episode	 Reward 	
0	-865.70699624	
1	-1123.59064643	
2	-1148.20556634	
3	-127.486677349	
4	-865.903711662	
5	-626.588659207	
6	-1063.23111493	
7	-0.3716818132	
8	-990.763158095	
9	-1148.88723424	
10	-629.662731238	
11	-751.320504002	
12	-1457.69110629	
13	-1522.41674003	
14	-1066.05417905	
15	-1532.19788209	
16	-128.072176093	
17	-1014.3443311	
18	-1062.90114313	
19	-1276.65116972	
20	-126.53628865	
21	-1163.55032735	
22	-1729.73064822	
23	-0.4936335989	
24	-1041.68519688	
25	-875.431496156	
26	-1516.35037312	
27	-1108.87603497	
28	-1093.6842695	
29	-1505.98988521	
30	-1737.3018228	
31	-1510.97690122	
32	-127.144482515	
33	-983.92293219	
34	-1135.21039072	
35	-1334.99154763	
36	-1115.18341142	
37	-1518.03685312	
38	-967.853258067	
39	-892.610603507	
40	-1039.26272354	
41	-1674.11128472	
42	-1738.89596895	
43	-1656.71290805	
44	-251.364495704	
45	-1253.81408652	
46	-1012.55420325	
47	-994.406775758	
48	-1158.90131316	
49	-0.7541005961	
50	-1.0460661998	
51	-1138.33490137	
52	-872.805773639	
53	-1402.61357291	
54	-832.28533327	
55	-1020.21784736	
56	-1728.65139696	
57	-1141.72213743	
58	-1465.65536506	
59	-1360.79260436	
60	-124.409866719	
61	-1253.04781392	
62	-1733.37937468	
63	-1719.9750443	
64	-1729.69967722	
65	-1310.84969166	
66	-1121.39609173	
67	-125.731288088	
68	-990.260234129	
69	-1420.62843256	
70	-1186.87863444	
71	-127.523301972	
72	-1705.73648775	
73	-1544.54877618	
74	-125.646218799	
75	-1107.42046864	
76	-1247.56977014	
77	-126.469855013	
78	-1730.2247164	
79	-127.558892028	
80	-1312.12771517	
81	-995.660211183	
82	-1500.19240595	
83	-1325.39961931	
84	-252.758467137	
85	-885.074228197	
86	-1326.26289559	
87	-1287.89788445	
88	-1732.21091966	
89	-1350.29816276	
90	-1730.03263553	
91	-1357.05685015	
92	-1589.43555959	
93	-1233.91856406	
94	-125.276742363	
95	-251.564668817	
96	-1136.01647493	
97	-1551.73134692	
98	-1731.47340208	
99	-1092.40463602	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.001	
 TAU	0.001	
 batch size	64	
 reward	 Param to be learned 	
 Single filter for rv 		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-894.626241279	
300	-1389.80205631	
400	-1218.171562	
500	-1257.14518361	
600	-1401.51195078	
700	-1423.68693443	
800	-1431.46730265	
900	-1292.28886258	
Time Training (1000episodes)	4817.1454656124	
Evaluation Episode	 Reward 	
0	-1351.48551561	
1	-1433.36566069	
2	-1541.39805557	
3	-1469.24922473	
4	-1731.8171117	
5	-1469.74756869	
6	-1158.64247916	
7	-1167.68028277	
8	-1700.10611913	
9	-1353.75404703	
10	-1160.82822822	
11	-1313.61241744	
12	-1373.03309213	
13	-1373.28230025	
14	-1378.70301029	
15	-1512.60547769	
16	-1368.09685567	
17	-1681.7376331	
18	-1420.47769414	
19	-1368.53169228	
20	-1704.16613284	
21	-1618.48768051	
22	-1676.55156605	
23	-1676.85318312	
24	-1255.61791734	
25	-948.8398883	
26	-868.566678217	
27	-1136.38444348	
28	-1345.7378711	
29	-1365.82280956	
30	-1732.52068623	
31	-1323.35065489	
32	-1494.51677014	
33	-1337.43832312	
34	-1289.95042606	
35	-1340.72447045	
36	-1724.47941383	
37	-1348.69822217	
38	-1564.57282072	
39	-1084.05697632	
40	-1175.62695595	
41	-1354.1367601	
42	-1372.95129965	
43	-1536.85029666	
44	-1375.19466517	
45	-1353.06689392	
46	-1382.06778524	
47	-1072.4859014	
48	-867.498871589	
49	-1609.32590282	
50	-1058.92287375	
51	-1730.37754695	
52	-1355.29914063	
53	-1283.90832487	
54	-1264.09594874	
55	-1311.31329341	
56	-1730.47660211	
57	-1583.04911051	
58	-1731.23713149	
59	-1058.80320051	
60	-1307.21368741	
61	-1315.03575786	
62	-1436.03236592	
63	-1252.34493278	
64	-1214.14049485	
65	-1573.44089746	
66	-1735.75205264	
67	-1332.55527627	
68	-1573.23351487	
69	-1357.24475246	
70	-832.713150616	
71	-868.551261175	
72	-1737.67283282	
73	-1355.10200961	
74	-1370.38629533	
75	-949.121291571	
76	-1147.10916265	
77	-1334.96932675	
78	-1330.27922653	
79	-1227.30522646	
80	-1133.99052384	
81	-1214.7187519	
82	-1470.73884564	
83	-1367.4322892	
84	-1632.50061255	
85	-831.709564792	
86	-1201.5894301	
87	-1315.6687677	
88	-1061.04107678	
89	-1729.32075271	
90	-1162.99295645	
91	-1301.9531128	
92	-1341.64214798	
93	-1356.83778802	
94	-1362.40529347	
95	-1605.71127074	
96	-1645.86953759	
97	-1342.99692351	
98	-1697.17089348	
99	-1393.82881072	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward	 Param to be learned 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1053.60493352	
300	-858.723101168	
400	-624.076649506	
500	-344.942845133	
600	-454.329626065	
700	-413.009871514	
800	-189.448801683	
900	-241.970963881	
1000	-384.661384449	
1100	-288.363314966	
1200	-285.445695334	
1300	-233.675676342	
1400	-312.979381491	
1500	-336.067913259	
1600	-182.452971851	
1700	-248.524770015	
1800	-204.613811869	
1900	-291.703341017	
2000	-255.160656759	
2100	-281.237663994	
2200	-167.990559391	
2300	-330.838022777	
2400	-173.722749251	
2500	-207.443158008	
2600	-301.313235293	
2700	-292.12927252	
2800	-226.293568269	
2900	-183.380213769	
3000	-227.754495999	
3100	-336.861291796	
3200	-111.270387491	
3300	-221.685522138	
3400	-212.455377558	
3500	-195.931770151	
3600	-248.983364034	
3700	-159.224395017	
3800	-264.254740219	
3900	-251.283844118	
Time Training (4000episodes)	20353.0050876141	
Evaluation Episode	 Reward 	
0	-1.5918136174	
1	-1.3900947958	
2	-235.677949044	
3	-126.10578067	
4	-366.218525978	
5	-125.826055755	
6	-357.992769574	
7	-119.518229136	
8	-121.603333937	
9	-119.722031929	
10	-626.816353532	
11	-121.86723439	
12	-480.059005751	
13	-123.726236929	
14	-124.897828365	
15	-121.638189137	
16	-125.175223346	
17	-488.752259527	
18	-120.583457104	
19	-122.286844754	
20	-561.521991873	
21	-125.875552642	
22	-476.428836011	
23	-122.575207434	
24	-125.016923954	
25	-124.671249566	
26	-241.871046218	
27	-125.850543652	
28	-528.282135502	
29	-588.928498011	
30	-245.714412825	
31	-123.45317929	
32	-124.412792931	
33	-122.458865327	
34	-124.206462362	
35	-122.921398195	
36	-126.476105091	
37	-122.075689052	
38	-123.664704663	
39	-522.101958229	
40	-237.220262037	
41	-122.842906807	
42	-122.716380685	
43	-356.078018304	
44	-234.037590873	
45	-243.307752134	
46	-121.41236023	
47	-495.57182692	
48	-241.63472629	
49	-476.287882236	
50	-355.181728651	
51	-240.745831781	
52	-124.497948875	
53	-366.603585176	
54	-236.130731615	
55	-126.100156214	
56	-122.426749101	
57	-533.289953945	
58	-241.618937388	
59	-1.7814870429	
60	-632.346142404	
61	-123.02168231	
62	-661.662469427	
63	-371.770468498	
64	-121.325692775	
65	-243.677945	
66	-238.204704007	
67	-618.380825708	
68	-126.546766872	
69	-529.81961227	
70	-125.280421945	
71	-126.857975632	
72	-123.372966497	
73	-124.602345269	
74	-237.504400318	
75	-357.452588032	
76	-119.725745397	
77	-122.651281453	
78	-241.919718345	
79	-122.800104928	
80	-124.94327217	
81	-246.072546476	
82	-593.990594198	
83	-234.287442092	
84	-125.176399889	
85	-516.733733028	
86	-122.196237205	
87	-244.077469719	
88	-359.798248816	
89	-122.454666807	
90	-359.449577406	
91	-125.32411466	
92	-244.462356045	
93	-124.274607351	
94	-241.351229206	
95	-369.417531615	
96	-354.681049991	
97	-123.455450447	
98	-509.669472047	
99	-121.284156464	
endExperiment		
		
numstates	100	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward	 Param to be learned 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1049.19050974	
300	-1158.42530105	
400	-1194.95829272	
500	-1099.05010359	
600	-1170.43008244	
700	-1171.62599958	
800	-1037.56706765	
900	-850.526004727	
1000	-1198.78157239	
1100	-1336.1084212	
1200	-1306.46997777	
1300	-1178.54966426	
1400	-1212.17980047	
1500	-1185.61500381	
1600	-956.53240062	
1700	-1532.30912039	
1800	-1012.79111719	
1900	-1259.26344073	
Time Training (2000episodes)	10878.0819745064	
Evaluation Episode	 Reward 	
0	-1674.62420423	
1	-1465.67689421	
2	-1425.59151542	
3	-880.680796063	
4	-1261.66617927	
5	-253.892659112	
6	-0.5673657193	
7	-998.221456898	
8	-793.922340114	
9	-1152.57033997	
10	-1158.33908764	
11	-879.252931094	
12	-1575.23844542	
13	-1111.49678099	
14	-0.6075290834	
15	-1008.24815928	
16	-1293.11870702	
17	-505.783485643	
18	-1488.33836067	
19	-1003.28018396	
20	-1565.2831409	
21	-0.5117570512	
22	-1391.22072303	
23	-128.738794563	
24	-1734.88770392	
25	-1644.81719764	
26	-1500.40986031	
27	-1449.98483441	
28	-1426.07989971	
29	-1633.05778822	
30	-1351.45573065	
31	-993.20150927	
32	-1280.07499316	
33	-987.682616796	
34	-756.391995729	
35	-1314.93040024	
36	-128.373538629	
37	-1571.85028809	
38	-1217.06133435	
39	-1667.9887354	
40	-0.6299067846	
41	-995.062056869	
42	-127.065950639	
43	-0.6530242348	
44	-1518.83822587	
45	-1126.78431695	
46	-1656.13154599	
47	-1516.43131699	
48	-127.9695131	
49	-1109.95314474	
50	-998.893065629	
51	-1491.47716977	
52	-829.854449498	
53	-1308.61869997	
54	-1154.72934766	
55	-1632.00100256	
56	-759.403773766	
57	-878.558663305	
58	-507.505808888	
59	-127.71401312	
60	-1410.91921565	
61	-254.502487974	
62	-1603.28898311	
63	-254.057691298	
64	-962.046134887	
65	-1124.51581666	
66	-1482.89996003	
67	-1720.09230557	
68	-380.875962067	
69	-1218.17886973	
70	-0.5392415656	
71	-995.621649126	
72	-848.236864575	
73	-761.12541682	
74	-1574.71735885	
75	-780.142621253	
76	-1723.7030468	
77	-1255.78488148	
78	-1020.30465253	
79	-1572.09699815	
80	-508.24064856	
81	-1058.466378	
82	-1392.02385486	
83	-126.950333234	
84	-765.595016341	
85	-956.410020414	
86	-127.965499929	
87	-1131.491643	
88	-1158.68207722	
89	-1088.55716078	
90	-839.037423638	
91	-1544.26000313	
92	-1729.98417302	
93	-1727.49514549	
94	-756.006451365	
95	-876.098839516	
96	-1430.22516619	
97	-1334.87801882	
98	-1347.55371618	
99	-1738.48846355	
endExperiment		
		
numstates	100	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.00005	
 TAU	0.001	
 batch size	64	
 reward	 Param to be learned 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1199.08711804	
300	-976.957134379	
400	-1072.61501406	
500	-935.039459045	
600	-969.840604759	
700	-1334.92972718	
800	-1062.97455296	
900	-1084.60964227	
1000	-897.54851442	
1100	-794.565312259	
1200	-1218.49373066	
1300	-560.92880777	
1400	-1175.78403646	
1500	-1156.37310537	
1600	-985.714424861	
1700	-1197.54023781	
1800	-1070.15369914	
1900	-886.61182793	
Time Training (2000episodes)	15551.3057596684	
Evaluation Episode	 Reward 	
0	-1349.18413248	
1	-1369.09815272	
2	-1238.14868798	
3	-1528.20947551	
4	-1156.94620597	
5	-1185.35101405	
6	-126.836457841	
7	-1531.89507639	
8	-882.606145817	
9	-126.515625731	
10	-1420.93504296	
11	-1141.22845451	
12	-126.377052998	
13	-124.611583568	
14	-1410.7631596	
15	-0.1553045156	
16	-126.924579206	
17	-1592.28530428	
18	-1702.58472243	
19	-1615.14862427	
20	-1198.41988342	
21	-1263.23669367	
22	-1728.94864799	
23	-0.2424228922	
24	-1194.71724688	
25	-1061.99041722	
26	-1187.95857848	
27	-125.456985763	
28	-948.021706202	
29	-1173.62029129	
30	-626.531466171	
31	-1234.24731081	
32	-956.944733804	
33	-994.6888563	
34	-875.437600889	
35	-1434.66630477	
36	-1366.76049879	
37	-126.466498246	
38	-125.410210939	
39	-0.8414079908	
40	-1684.13931387	
41	-988.955976678	
42	-1734.14467702	
43	-1432.70910797	
44	-1635.44120907	
45	-1729.59842668	
46	-1142.9889969	
47	-1082.41132318	
48	-895.09657042	
49	-1737.99626817	
50	-1730.2190539	
51	-1227.28753266	
52	-500.598020754	
53	-1448.51477099	
54	-1098.21293674	
55	-1302.13101767	
56	-1349.2695099	
57	-995.801146632	
58	-1402.81379414	
59	-961.926661676	
60	-0.5285121904	
61	-375.29306552	
62	-1239.82664955	
63	-1734.75579385	
64	-1366.81408526	
65	-1518.89041824	
66	-1633.98233968	
67	-1118.26871126	
68	-127.058732247	
69	-1268.32115032	
70	-251.544307831	
71	-989.230238083	
72	-1154.28383121	
73	-124.533340501	
74	-1434.49570675	
75	-1188.60854019	
76	-1719.01520557	
77	-124.867288352	
78	-126.245565151	
79	-1443.47955253	
80	-1096.54641792	
81	-1220.55306875	
82	-126.368115589	
83	-990.738018863	
84	-1247.9684806	
85	-1290.44460469	
86	-1219.93495388	
87	-1294.61722595	
88	-876.54216637	
89	-0.4067363861	
90	-1038.76971576	
91	-1730.98603317	
92	-377.928610106	
93	-0.1554467476	
94	-1334.1708881	
95	-251.29044308	
96	-1368.4960692	
97	-1142.03444886	
98	-1733.23339813	
99	-502.080066668	
endExperiment		
		
numstates	500	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	50	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward	 Param to be learned 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1095.89516272	
300	-1197.17716642	
400	-1095.13763082	
500	-1249.36405317	
600	-850.966442088	
700	-774.945213073	
800	-1252.16851282	
900	-1169.37259522	
1000	-874.006265603	
1100	-1062.99526985	
1200	-1302.22571608	
1300	-1260.45092325	
1400	-767.433082266	
1500	-727.404590588	
1600	-765.10446279	
1700	-917.791409699	
1800	-1132.7679999	
1900	-1150.43939283	
2000	-821.861756387	
2100	-881.06188444	
2200	-1073.33478272	
2300	-989.659026972	
2400	-702.444853249	
2500	-1163.24102413	
2600	-650.945935764	
2700	-1140.41272441	
2800	-863.695809469	
2900	-496.937573524	
3000	-1094.1832604	
3100	-1398.16383605	
3200	-1132.07912059	
3300	-882.22909685	
3400	-1010.0040656	
3500	-679.412651428	
3600	-1060.75283225	
3700	-1027.47769308	
3800	-525.842024417	
3900	-733.417891635	
4000	-302.115943028	
4100	-512.182965872	
4200	-363.912373965	
4300	-441.849966267	
4400	-366.221390004	
4500	-517.834919637	
4600	-446.548502654	
4700	-358.77482508	
4800	-340.073610308	
4900	-292.47454307	
Time Training (5000episodes)	26997.7748465538	
Evaluation Episode	 Reward 	
0	-251.645642457	
1	-357.157614584	
2	-243.345736449	
3	-124.087975521	
4	-366.092035726	
5	-473.750671996	
6	-722.44566725	
7	-126.477280423	
8	-123.842018433	
9	-250.543858435	
10	-241.585891131	
11	-252.172057605	
12	-0.1990150094	
13	-639.125959529	
14	-364.229300158	
15	-365.651737665	
16	-252.13694648	
17	-646.77311191	
18	-367.152105321	
19	-369.33875393	
20	-247.45209453	
21	-634.359894592	
22	-480.687298714	
23	-125.48537526	
24	-359.307431155	
25	-654.392869411	
26	-123.257627856	
27	-246.291853993	
28	-126.810435806	
29	-0.1303923661	
30	-359.466082886	
31	-616.070612207	
32	-368.264971769	
33	-251.84625217	
34	-120.017304809	
35	-493.897022128	
36	-123.206741219	
37	-486.227149496	
38	-496.39354618	
39	-248.915836457	
40	-127.389573963	
41	-124.677464737	
42	-494.226560586	
43	-617.201846981	
44	-126.820091066	
45	-119.85981529	
46	-620.100521969	
47	-0.8699827234	
48	-124.28511121	
49	-0.4930046654	
50	-360.116954067	
51	-123.291444838	
52	-359.379396826	
53	-0.2919383794	
54	-123.16734792	
55	-244.403691853	
56	-361.558993715	
57	-251.839394154	
58	-707.24964912	
59	-237.504975464	
60	-367.658066361	
61	-644.483481806	
62	-361.386229444	
63	-126.034574304	
64	-246.833205928	
65	-242.617603287	
66	-246.840098125	
67	-0.2997958154	
68	-246.200868723	
69	-248.251085405	
70	-242.019229585	
71	-120.386834546	
72	-240.865799153	
73	-483.8070238	
74	-645.325943055	
75	-603.953048344	
76	-0.4725981421	
77	-252.49078128	
78	-237.766548835	
79	-567.363046461	
80	-250.231663829	
81	-120.529676928	
82	-489.813039647	
83	-365.653551989	
84	-493.418272206	
85	-601.953563616	
86	-240.997382501	
87	-243.795231132	
88	-249.922370222	
89	-125.09749619	
90	-252.054354079	
91	-0.4968267975	
92	-596.43138128	
93	-253.332239931	
94	-494.639309355	
95	-122.239258747	
96	-360.917900918	
97	-247.478839579	
98	-248.388251405	
99	-368.635693527	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	30	
 channel_q	15	
hidden layer size	50	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward	 Param to be learned 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-930.435084709	
300	-1014.01003654	
400	-1322.50087305	
500	-1105.10969315	
600	-907.869322287	
700	-600.834256481	
800	-869.418737588	
900	-827.275486579	
Time Training (1000episodes)	4884.5301947594	
Evaluation Episode	 Reward 	
0	-1513.78945345	
1	-1209.10465016	
2	-1238.24312298	
3	-504.388452667	
4	-1295.62840358	
5	-883.114106766	
6	-1090.09424538	
7	-126.958509649	
8	-1310.90161303	
9	-253.615495951	
10	-974.733186125	
11	-1000.81570814	
12	-127.292362587	
13	-1732.41167363	
14	-891.41802744	
15	-505.942681842	
16	-999.915229277	
17	-1126.25810296	
18	-0.405830081	
19	-126.056529992	
20	-944.169923916	
21	-1560.81731233	
22	-126.984158461	
23	-1061.26319389	
24	-1125.3175348	
25	-1560.09719846	
26	-1234.43528008	
27	-1009.2993637	
28	-1145.38036465	
29	-1516.2160273	
30	-1376.03454016	
31	-971.807243856	
32	-1555.07078385	
33	-378.68213966	
34	-1477.8866669	
35	-127.674137824	
36	-1145.9891032	
37	-1730.64986115	
38	-1094.86448596	
39	-975.522594746	
40	-1730.3519202	
41	-1118.84339478	
42	-1401.99858404	
43	-1141.02706414	
44	-873.982618807	
45	-252.580892616	
46	-0.6817736575	
47	-956.90025299	
48	-1210.43771997	
49	-254.105728894	
50	-253.443807278	
51	-878.371742631	
52	-1730.05292472	
53	-1650.33146661	
54	-974.889324253	
55	-1331.643752	
56	-1316.26384083	
57	-1638.08052554	
58	-1274.05679975	
59	-905.534468432	
60	-126.861384411	
61	-1056.45582913	
62	-1730.73084023	
63	-127.715757102	
64	-127.983102532	
65	-1097.76967644	
66	-1733.00565322	
67	-1515.5771514	
68	-1544.64519757	
69	-1227.62922423	
70	-1166.76832909	
71	-1598.06931389	
72	-1375.97230788	
73	-1104.06667871	
74	-1710.97713304	
75	-879.929393134	
76	-1722.88202365	
77	-1327.91450687	
78	-1708.30984811	
79	-875.119733969	
80	-253.876799198	
81	-506.904037968	
82	-1468.52136929	
83	-885.605406619	
84	-890.439144597	
85	-1305.20804046	
86	-1710.61861563	
87	-1735.71346295	
88	-1422.31260874	
89	-1638.75881373	
90	-378.033633809	
91	-1511.35868949	
92	-1450.67709942	
93	-1110.14274652	
94	-879.168015966	
95	-1155.64541616	
96	-1.0840357051	
97	-1309.8760011	
98	-810.685727776	
99	-1015.17036121	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	30	
 channel_q	15	
hidden layer size	50	
 learning rate	0.01	
 TAU	0.001	
 batch size	64	
 reward	 Param to be learned 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1326.51132828	
300	-1289.89578011	
400	-1288.76234341	
500	-1413.89840538	
600	-1342.60012073	
700	-1356.9295837	
800	-1346.13372381	
900	-1371.54681237	
Time Training (1000episodes)	4848.8972988129	
Evaluation Episode	 Reward 	
0	-1431.4136173	
1	-843.651841868	
2	-1386.43383368	
3	-1538.29226995	
4	-954.244329843	
5	-1567.79795682	
6	-1649.80941088	
7	-1307.90434344	
8	-1352.33552561	
9	-1664.0289967	
10	-1630.19008028	
11	-1239.78697022	
12	-1402.14499884	
13	-1322.24418147	
14	-1332.05824976	
15	-1303.21023585	
16	-1732.52516995	
17	-1609.5043925	
18	-1180.9893428	
19	-1393.85857861	
20	-1061.22883143	
21	-1292.1227089	
22	-1394.61092297	
23	-1705.11337212	
24	-1120.82954949	
25	-1091.59755086	
26	-817.722828082	
27	-1453.40787397	
28	-830.850474835	
29	-1364.41523184	
30	-1145.14714741	
31	-1355.46542959	
32	-1373.69909003	
33	-1333.47555525	
34	-1398.94155471	
35	-1467.83021033	
36	-1047.50696318	
37	-1219.36351672	
38	-1730.02085547	
39	-944.244775789	
40	-1349.06878759	
41	-1583.42898835	
42	-1730.44265691	
43	-1351.69783369	
44	-1468.71028258	
45	-1333.56152095	
46	-1339.88761261	
47	-1179.82381565	
48	-1366.58321931	
49	-1181.58459686	
50	-1374.2870363	
51	-1521.05190712	
52	-1406.14698233	
53	-1138.77393814	
54	-1483.72374973	
55	-876.849024531	
56	-1346.55540135	
57	-1571.99802252	
58	-1353.75601126	
59	-1392.95560594	
60	-1628.35332324	
61	-1373.33867908	
62	-836.591591989	
63	-1052.45807026	
64	-1223.16394296	
65	-1730.30777488	
66	-1730.60394872	
67	-1373.13368203	
68	-1606.58399841	
69	-1394.22134931	
70	-1077.62213423	
71	-950.347649401	
72	-1293.54037159	
73	-1377.92432408	
74	-1739.07395395	
75	-1593.49623638	
76	-1180.02619879	
77	-1383.06981691	
78	-1337.95593118	
79	-1467.09746297	
80	-1368.73186674	
81	-1254.96463693	
82	-1398.66408854	
83	-1406.68951142	
84	-1337.74747592	
85	-1313.28335666	
86	-1637.69436823	
87	-1528.21374695	
88	-1291.93556357	
89	-1735.16975981	
90	-1348.27904325	
91	-1613.07972909	
92	-1707.33803777	
93	-1373.99257155	
94	-747.858762602	
95	-1366.71594682	
96	-1351.59473961	
97	-1452.75269116	
98	-1275.66123097	
99	-1447.67122863	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	30	
 channel_q	15	
hidden layer size	50	
 learning rate	0.001	
 TAU	0.001	
 batch size	64	
 reward	 Param to be learned 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1420.61557298	
300	-1378.90030551	
400	-1238.06022142	
500	-1171.81495496	
600	-1356.78210725	
700	-1472.41567973	
800	-1408.67875009	
900	-1232.57691531	
Time Training (1000episodes)	4747.4913015366	
Evaluation Episode	 Reward 	
0	-1637.18225302	
1	-1728.01854867	
2	-1228.37921734	
3	-1362.12137501	
4	-1064.66288515	
5	-1439.25150438	
6	-1637.55165898	
7	-1312.0803864	
8	-976.233844154	
9	-1330.51160921	
10	-1373.70607634	
11	-1159.09574706	
12	-1341.68627303	
13	-1350.88498078	
14	-1729.50567659	
15	-1738.12927521	
16	-1141.07760215	
17	-1383.31937728	
18	-1732.72311439	
19	-1177.78638079	
20	-1347.61771928	
21	-1602.74487726	
22	-1278.35573436	
23	-1130.59857255	
24	-1385.05385464	
25	-1164.17592373	
26	-1359.00223111	
27	-1356.94072158	
28	-1683.28327721	
29	-1058.50855722	
30	-1729.09100648	
31	-1376.16069026	
32	-1174.77867285	
33	-1304.33316803	
34	-1051.6528054	
35	-1361.57865154	
36	-1041.79906076	
37	-1380.83025838	
38	-1161.9287741	
39	-1218.83768363	
40	-1315.61448297	
41	-1346.86876417	
42	-1361.63874015	
43	-1362.05850294	
44	-1290.62694561	
45	-1610.07817066	
46	-935.157467312	
47	-1733.58661704	
48	-1222.805807	
49	-1351.81751278	
50	-1669.6497181	
51	-1236.12184139	
52	-1327.07987109	
53	-1365.19967841	
54	-1683.57675135	
55	-1320.35335915	
56	-1657.5397823	
57	-1161.6103341	
58	-1418.78212652	
59	-1383.91686003	
60	-1340.7302177	
61	-1408.97249443	
62	-1348.79204605	
63	-1628.30723265	
64	-1480.68984427	
65	-1503.18904388	
66	-1346.8921564	
67	-1350.4964735	
68	-1313.14655401	
69	-1365.28088506	
70	-1416.49819263	
71	-1060.06017088	
72	-1369.3211554	
73	-1734.22255034	
74	-769.988642822	
75	-954.281853613	
76	-1236.58222483	
77	-1394.59989077	
78	-1583.05325695	
79	-1358.10940021	
80	-1367.28960219	
81	-1661.96454497	
82	-1297.17570533	
83	-1168.43811973	
84	-1507.89186996	
85	-1568.25262444	
86	-1192.99925958	
87	-1033.1511879	
88	-1647.71756528	
89	-1264.1263891	
90	-1203.54625638	
91	-1383.45507202	
92	-960.555036981	
93	-1321.43041734	
94	-1635.94485243	
95	-1044.6653477	
96	-1376.50930611	
97	-941.347072331	
98	-1540.56957185	
99	-1040.38566477	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	30	
 channel_q	15	
hidden layer size	50	
 learning rate	0.001	
 TAU	0.01	
 batch size	64	
 reward	 Param to be learned 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1356.1174732	
300	-1354.96023265	
400	-1458.38361544	
500	-1250.0329049	
600	-1259.60265635	
700	-1320.65575523	
800	-1397.26228345	
900	-1405.10091804	
1000	-1441.39600082	
1100	-1277.22277755	
1200	-1424.45185484	
1300	-1355.81390795	
1400	-1385.06707281	
1500	-1343.10416178	
1600	-1382.02714819	
1700	-1377.46578559	
1800	-1287.34929032	
1900	-1321.7383646	
2000	-1253.1626496	
2100	-1222.09607871	
2200	-1412.30922209	
2300	-1346.27277658	
2400	-1298.81710451	
2500	-1257.12958111	
2600	-1314.26758476	
2700	-1430.44719388	
2800	-1351.23547924	
2900	-1312.24812401	
3000	-1360.18397076	
3100	-1391.95340333	
3200	-1383.00583145	
3300	-1298.88727198	
3400	-1263.13767008	
3500	-1285.64882496	
3600	-1397.14253527	
3700	-1353.83438368	
3800	-1479.28147101	
3900	-1259.54832609	
Time Training (4000episodes)	20572.0075659752	
Evaluation Episode	 Reward 	
0	-1625.77182942	
1	-1036.10904898	
2	-1333.47265489	
3	-1527.84637896	
4	-1350.66085464	
5	-1187.12669397	
6	-1133.69070073	
7	-1370.1998263	
8	-1380.8424221	
9	-1727.22713442	
10	-1101.61147791	
11	-1358.73184988	
12	-1654.1062065	
13	-1375.48425529	
14	-1065.87695527	
15	-900.14650164	
16	-1600.62267107	
17	-1468.52634856	
18	-1394.31191557	
19	-1350.20012649	
20	-1352.30400644	
21	-1635.03451669	
22	-1373.74080137	
23	-1625.46259718	
24	-1269.08294498	
25	-1073.39679299	
26	-1731.58991141	
27	-1377.6406474	
28	-856.257594256	
29	-1491.23089276	
30	-1646.65015956	
31	-1655.02609037	
32	-1376.01675922	
33	-1188.27621969	
34	-1409.27989373	
35	-1426.2372357	
36	-1380.66687593	
37	-1675.57300259	
38	-1361.2703189	
39	-1493.2738954	
40	-1581.21474275	
41	-1130.02864722	
42	-1389.00045488	
43	-1165.02090583	
44	-1351.55637636	
45	-1317.02245799	
46	-1345.26628411	
47	-1353.37422952	
48	-1729.51511031	
49	-1584.03422608	
50	-1349.92732675	
51	-1734.27411951	
52	-1693.50113455	
53	-1072.01700271	
54	-1220.77942403	
55	-727.975672517	
56	-1255.18025035	
57	-1366.04528485	
58	-1474.88595766	
59	-1393.31940007	
60	-1331.83981807	
61	-1496.15944082	
62	-1148.08999953	
63	-1061.35179452	
64	-1356.65616666	
65	-948.476350715	
66	-1071.30116629	
67	-1285.17208618	
68	-1675.53166684	
69	-1698.08118687	
70	-1735.38171469	
71	-1278.73818072	
72	-1279.63756121	
73	-1046.76338821	
74	-1181.56517872	
75	-1729.3002155	
76	-1368.26493003	
77	-1335.27810764	
78	-1732.1237799	
79	-1469.71079217	
80	-1173.22795188	
81	-1347.29007806	
82	-1322.7694393	
83	-1164.23726486	
84	-1125.92593057	
85	-1169.86610206	
86	-1388.10673259	
87	-1585.28087935	
88	-1454.82625348	
89	-1486.41436477	
90	-1508.66982246	
91	-808.599883634	
92	-1675.16705631	
93	-1359.42619387	
94	-1350.10984568	
95	-948.479225943	
96	-1312.95673589	
97	-1038.94566095	
98	-843.634306453	
99	-1361.71845131	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	30	
 channel_q	15	
hidden layer size	50	
 learning rate	0.001	
 TAU	0.0001	
 batch size	64	
 reward	 Param to be learned 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1310.14560055	
300	-1378.88250671	
400	-1444.55222798	
500	-1304.62495949	
600	-1372.81600616	
700	-1198.36024059	
800	-1409.56516956	
900	-1295.69379895	
Time Training (1000episodes)	4760.6692636013	
Evaluation Episode	 Reward 	
0	-1172.08429626	
1	-1166.21474515	
2	-850.400127968	
3	-1518.77126918	
4	-950.191898244	
5	-1367.03981808	
6	-1198.80641794	
7	-1382.40344571	
8	-1529.54382067	
9	-1388.83543431	
10	-1186.66189161	
11	-1483.73727177	
12	-1219.42701776	
13	-1204.56946705	
14	-1373.93103149	
15	-1157.44459029	
16	-1374.3174137	
17	-720.829792891	
18	-1060.36787306	
19	-1668.853431	
20	-1728.78166954	
21	-1356.75516489	
22	-1305.65155644	
23	-1670.55765811	
24	-952.181459135	
25	-949.187223482	
26	-1265.32155751	
27	-1401.34651322	
28	-1239.92527088	
29	-1682.36230472	
30	-1365.3961407	
31	-1076.56412843	
32	-1226.33414285	
33	-730.523964508	
34	-1627.510625	
35	-1368.51934675	
36	-1347.29171375	
37	-1389.75276331	
38	-1341.4396692	
39	-1373.96662439	
40	-1729.5694225	
41	-836.450880291	
42	-1651.62100681	
43	-1193.58091017	
44	-949.768453623	
45	-1175.22195236	
46	-1456.55491595	
47	-1175.07533063	
48	-1059.32594659	
49	-1328.10766058	
50	-1572.58846258	
51	-1366.57020779	
52	-1174.8641036	
53	-1482.78149068	
54	-950.64827847	
55	-966.720418453	
56	-1729.08774531	
57	-1170.37388312	
58	-1256.41500688	
59	-1728.80995559	
60	-1332.8611209	
61	-1342.03606279	
62	-1174.96935572	
63	-1357.76442622	
64	-1362.09056222	
65	-1427.42429991	
66	-1353.43602212	
67	-1280.3270195	
68	-1355.5953352	
69	-1367.96188169	
70	-1169.57015392	
71	-1178.4697127	
72	-1522.36419409	
73	-1218.36935092	
74	-1732.72865516	
75	-1729.52961422	
76	-1140.9716297	
77	-1494.08982817	
78	-1737.53429079	
79	-1592.15821457	
80	-1578.18794436	
81	-1064.83572347	
82	-1368.72542017	
83	-1369.33661994	
84	-1409.99462711	
85	-1254.07677666	
86	-1389.59907435	
87	-886.983240852	
88	-1451.42503526	
89	-1729.27569366	
90	-1252.31505408	
91	-1346.53897841	
92	-1704.12308671	
93	-1465.94956686	
94	-1221.1249501	
95	-1517.31511196	
96	-1343.34447981	
97	-722.143226114	
98	-1350.57257325	
99	-1616.46043173	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	30	
 channel_q	15	
hidden layer size	150	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward	 [[[ -0.        ]   [ -0.16      ]   [ -0.31999999]   [ -0.47999999]   [ -0.63999999]   [ -0.79999995]   [ -0.95999998]   [ -1.12      ]   [ -1.27999997]   [ -1.43999994]   [ -1.5999999 ]   [ -1.75999999]   [ -1.91999996]   [ -2.07999992]   [ -2.24000001]   [ -2.39999986]   [ -2.55999994]   [ -2.72000003]   [ -2.87999988]   [ -3.03999996]   [ -3.19999981]   [ -3.3599999 ]   [ -3.51999998]   [ -3.67999983]   [ -3.83999991]   [ -4.        ]   [ -4.15999985]   [ -4.31999969]   [ -4.48000002]   [ -4.63999987]   [ -4.79999971]   [ -4.96000004]   [ -5.11999989]   [ -5.27999973]   [ -5.44000006]   [ -5.5999999 ]   [ -5.75999975]   [ -5.92000008]   [ -6.07999992]   [ -6.23999977]   [ -6.39999962]   [ -6.55999994]   [ -6.71999979]   [ -6.87999964]   [ -7.03999996]   [ -7.19999981]   [ -7.35999966]   [ -7.51999998]   [ -7.67999983]   [ -7.83999968]   [ -8.        ]   [ -8.15999985]   [ -8.31999969]   [ -8.47999954]   [ -8.63999939]   [ -8.80000019]   [ -8.96000004]   [ -9.11999989]   [ -9.27999973]   [ -9.43999958]   [ -9.59999943]   [ -9.76000023]   [ -9.92000008]   [-10.07999992]   [-10.23999977]   [-10.39999962]   [-10.55999947]   [-10.71999931]   [-10.88000011]   [-11.03999996]   [-11.19999981]   [-11.35999966]   [-11.5199995 ]   [-11.67999935]   [-11.84000015]   [-12.        ]   [-12.15999985]   [-12.31999969]   [-12.47999954]   [-12.63999939]   [-12.79999924]   [-12.96000004]   [-13.11999989]   [-13.27999973]   [-13.43999958]   [-13.59999943]   [-13.75999928]   [-13.92000008]   [-14.07999992]   [-14.23999977]   [-14.39999962]   [-14.55999947]   [-14.71999931]   [-14.88000011]   [-15.03999996]   [-15.19999981]   [-15.35999966]   [-15.5199995 ]   [-15.67999935]   [-15.8399992 ]   [-15.8399992 ]   [-15.67999935]   [-15.5199995 ]   [-15.35999966]   [-15.19999981]   [-15.03999996]   [-14.88000011]   [-14.71999931]   [-14.55999947]   [-14.39999962]   [-14.23999977]   [-14.07999992]   [-13.92000008]   [-13.75999928]   [-13.59999943]   [-13.43999958]   [-13.27999973]   [-13.11999989]   [-12.96000004]   [-12.79999924]   [-12.63999939]   [-12.47999954]   [-12.31999969]   [-12.15999985]   [-12.        ]   [-11.84000015]   [-11.67999935]   [-11.5199995 ]   [-11.35999966]   [-11.19999981]   [-11.03999996]   [-10.88000011]   [-10.71999931]   [-10.55999947]   [-10.39999962]   [-10.23999977]   [-10.07999992]   [ -9.92000008]   [ -9.76000023]   [ -9.59999943]   [ -9.43999958]   [ -9.27999973]   [ -9.11999989]   [ -8.96000004]   [ -8.80000019]   [ -8.63999939]   [ -8.47999954]   [ -8.31999969]   [ -8.15999985]   [ -8.        ]   [ -7.83999968]   [ -7.67999983]   [ -7.51999998]   [ -7.35999966]   [ -7.19999981]   [ -7.03999996]   [ -6.87999964]   [ -6.71999979]   [ -6.55999994]   [ -6.39999962]   [ -6.23999977]   [ -6.07999992]   [ -5.92000008]   [ -5.75999975]   [ -5.5999999 ]   [ -5.44000006]   [ -5.27999973]   [ -5.11999989]   [ -4.96000004]   [ -4.79999971]   [ -4.63999987]   [ -4.48000002]   [ -4.31999969]   [ -4.15999985]   [ -4.        ]   [ -3.83999991]   [ -3.67999983]   [ -3.51999998]   [ -3.3599999 ]   [ -3.19999981]   [ -3.03999996]   [ -2.87999988]   [ -2.72000003]   [ -2.55999994]   [ -2.39999986]   [ -2.24000001]   [ -2.07999992]   [ -1.91999996]   [ -1.75999999]   [ -1.5999999 ]   [ -1.43999994]   [ -1.27999997]   [ -1.12      ]   [ -0.95999998]   [ -0.79999995]   [ -0.63999999]   [ -0.47999999]   [ -0.31999999]   [ -0.16      ]   [ -0.        ]]] 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1124.48174628	
300	-1115.99944174	
400	-950.199394766	
500	-1009.15721393	
600	-806.713575073	
700	-1177.91583166	
800	-814.317293404	
900	-695.67571778	
Time Training (1000episodes)	5272.1785509586	
Evaluation Episode	 Reward 	
0	-1294.55921647	
1	-1166.872235	
2	-1120.36966866	
3	-119.306284439	
4	-1164.45465071	
5	-1454.39937751	
6	-1189.40827753	
7	-120.64879495	
8	-1033.0847762	
9	-756.672315937	
10	-1300.7972578	
11	-125.406951968	
12	-125.326888262	
13	-121.001045949	
14	-1376.46960067	
15	-1350.08626778	
16	-1232.37463147	
17	-121.513805866	
18	-1597.24231139	
19	-1099.98378409	
20	-0.5249235435	
21	-1174.42375663	
22	-1735.13256433	
23	-121.965759092	
24	-1508.67753185	
25	-950.302662257	
26	-121.113359932	
27	-1728.76684045	
28	-1691.02839381	
29	-1458.14251504	
30	-1331.67972641	
31	-1464.61806723	
32	-1501.21442389	
33	-1711.77636564	
34	-122.128341321	
35	-1565.77249651	
36	-1649.00257369	
37	-839.71844186	
38	-1729.95531917	
39	-120.923331647	
40	-120.982869157	
41	-1628.92772766	
42	-239.279742211	
43	-717.193806731	
44	-1714.44563961	
45	-120.886943896	
46	-950.094050121	
47	-120.627334643	
48	-1732.26191109	
49	-1248.25069258	
50	-1402.7504333	
51	-1630.30028806	
52	-1305.57780967	
53	-1047.40378063	
54	-1474.75631169	
55	-119.825922541	
56	-949.466344213	
57	-125.070321105	
58	-1312.33996427	
59	-1175.80364436	
60	-1716.245696	
61	-125.582134136	
62	-119.311168124	
63	-1060.23431075	
64	-1197.82961331	
65	-948.897810409	
66	-1729.94008236	
67	-1720.80420096	
68	-957.157580891	
69	-952.97055954	
70	-1076.66905273	
71	-0.3934848034	
72	-1414.9330075	
73	-0.4881178848	
74	-1718.18959642	
75	-1308.39802857	
76	-1380.16751586	
77	-1531.04562456	
78	-120.823359099	
79	-1669.33897584	
80	-1294.3280711	
81	-0.6813954627	
82	-1053.18386411	
83	-120.975037487	
84	-1295.62337635	
85	-1504.22064106	
86	-1165.18238459	
87	-1692.29271196	
88	-1247.51015939	
89	-121.822513021	
90	-1398.54326089	
91	-121.834918369	
92	-1248.65826024	
93	-122.79089548	
94	-727.458660047	
95	-967.343795824	
96	-125.101786587	
97	-1723.21965857	
98	-1171.76817787	
99	-0.5517153207	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward	 [[[ -0.        ]   [ -0.16      ]   [ -0.31999999]   [ -0.47999999]   [ -0.63999999]   [ -0.79999995]   [ -0.95999998]   [ -1.12      ]   [ -1.27999997]   [ -1.43999994]   [ -1.5999999 ]   [ -1.75999999]   [ -1.91999996]   [ -2.07999992]   [ -2.24000001]   [ -2.39999986]   [ -2.55999994]   [ -2.72000003]   [ -2.87999988]   [ -3.03999996]   [ -3.19999981]   [ -3.3599999 ]   [ -3.51999998]   [ -3.67999983]   [ -3.83999991]   [ -4.        ]   [ -4.15999985]   [ -4.31999969]   [ -4.48000002]   [ -4.63999987]   [ -4.79999971]   [ -4.96000004]   [ -5.11999989]   [ -5.27999973]   [ -5.44000006]   [ -5.5999999 ]   [ -5.75999975]   [ -5.92000008]   [ -6.07999992]   [ -6.23999977]   [ -6.39999962]   [ -6.55999994]   [ -6.71999979]   [ -6.87999964]   [ -7.03999996]   [ -7.19999981]   [ -7.35999966]   [ -7.51999998]   [ -7.67999983]   [ -7.83999968]   [ -8.        ]   [ -8.15999985]   [ -8.31999969]   [ -8.47999954]   [ -8.63999939]   [ -8.80000019]   [ -8.96000004]   [ -9.11999989]   [ -9.27999973]   [ -9.43999958]   [ -9.59999943]   [ -9.76000023]   [ -9.92000008]   [-10.07999992]   [-10.23999977]   [-10.39999962]   [-10.55999947]   [-10.71999931]   [-10.88000011]   [-11.03999996]   [-11.19999981]   [-11.35999966]   [-11.5199995 ]   [-11.67999935]   [-11.84000015]   [-12.        ]   [-12.15999985]   [-12.31999969]   [-12.47999954]   [-12.63999939]   [-12.79999924]   [-12.96000004]   [-13.11999989]   [-13.27999973]   [-13.43999958]   [-13.59999943]   [-13.75999928]   [-13.92000008]   [-14.07999992]   [-14.23999977]   [-14.39999962]   [-14.55999947]   [-14.71999931]   [-14.88000011]   [-15.03999996]   [-15.19999981]   [-15.35999966]   [-15.5199995 ]   [-15.67999935]   [-15.8399992 ]   [-15.8399992 ]   [-15.67999935]   [-15.5199995 ]   [-15.35999966]   [-15.19999981]   [-15.03999996]   [-14.88000011]   [-14.71999931]   [-14.55999947]   [-14.39999962]   [-14.23999977]   [-14.07999992]   [-13.92000008]   [-13.75999928]   [-13.59999943]   [-13.43999958]   [-13.27999973]   [-13.11999989]   [-12.96000004]   [-12.79999924]   [-12.63999939]   [-12.47999954]   [-12.31999969]   [-12.15999985]   [-12.        ]   [-11.84000015]   [-11.67999935]   [-11.5199995 ]   [-11.35999966]   [-11.19999981]   [-11.03999996]   [-10.88000011]   [-10.71999931]   [-10.55999947]   [-10.39999962]   [-10.23999977]   [-10.07999992]   [ -9.92000008]   [ -9.76000023]   [ -9.59999943]   [ -9.43999958]   [ -9.27999973]   [ -9.11999989]   [ -8.96000004]   [ -8.80000019]   [ -8.63999939]   [ -8.47999954]   [ -8.31999969]   [ -8.15999985]   [ -8.        ]   [ -7.83999968]   [ -7.67999983]   [ -7.51999998]   [ -7.35999966]   [ -7.19999981]   [ -7.03999996]   [ -6.87999964]   [ -6.71999979]   [ -6.55999994]   [ -6.39999962]   [ -6.23999977]   [ -6.07999992]   [ -5.92000008]   [ -5.75999975]   [ -5.5999999 ]   [ -5.44000006]   [ -5.27999973]   [ -5.11999989]   [ -4.96000004]   [ -4.79999971]   [ -4.63999987]   [ -4.48000002]   [ -4.31999969]   [ -4.15999985]   [ -4.        ]   [ -3.83999991]   [ -3.67999983]   [ -3.51999998]   [ -3.3599999 ]   [ -3.19999981]   [ -3.03999996]   [ -2.87999988]   [ -2.72000003]   [ -2.55999994]   [ -2.39999986]   [ -2.24000001]   [ -2.07999992]   [ -1.91999996]   [ -1.75999999]   [ -1.5999999 ]   [ -1.43999994]   [ -1.27999997]   [ -1.12      ]   [ -0.95999998]   [ -0.79999995]   [ -0.63999999]   [ -0.47999999]   [ -0.31999999]   [ -0.16      ]   [ -0.        ]]] 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1246.31361332	
300	-1253.38210477	
400	-1296.9786826	
500	-1331.74545965	
600	-1212.74546884	
700	-1320.14191773	
800	-1277.10732356	
900	-1135.00934904	
Time Training (1000episodes)	5348.061375618	
Evaluation Episode	 Reward 	
0	-1174.20078319	
1	-1159.00729342	
2	-1008.71651397	
3	-1176.36551349	
4	-1164.3162079	
5	-1157.49100854	
6	-1145.81405199	
7	-1718.71054344	
8	-1149.06314961	
9	-1163.59312439	
10	-1175.15134725	
11	-898.655533416	
12	-892.246647821	
13	-1173.34206124	
14	-761.219071738	
15	-1169.18975391	
16	-1164.45312903	
17	-1172.0871786	
18	-1155.68783435	
19	-1033.79204866	
20	-1000.5933823	
21	-1162.13686098	
22	-1171.31730147	
23	-1219.43751492	
24	-1020.46449156	
25	-1168.86397414	
26	-988.962898406	
27	-882.034149018	
28	-1169.77544573	
29	-1730.80174444	
30	-991.537241739	
31	-1170.70064035	
32	-989.795536859	
33	-1734.86471709	
34	-1159.35075631	
35	-995.087737768	
36	-1734.28383318	
37	-1171.47090829	
38	-892.469760482	
39	-1735.53029502	
40	-1165.23636554	
41	-919.131555551	
42	-998.638540323	
43	-1730.05155874	
44	-1170.2433345	
45	-996.0368012	
46	-890.150274193	
47	-1129.8601409	
48	-1141.77752743	
49	-1158.7318707	
50	-1163.71952157	
51	-1175.0192503	
52	-1161.36150633	
53	-994.521732024	
54	-891.877223368	
55	-1169.42924299	
56	-990.979637466	
57	-897.901293506	
58	-1137.94928348	
59	-1152.24616871	
60	-1178.57543864	
61	-1163.59571037	
62	-998.587934008	
63	-880.428080148	
64	-993.252258651	
65	-895.628353973	
66	-1035.32636631	
67	-1071.80647495	
68	-877.990489466	
69	-1154.72863768	
70	-920.346362953	
71	-874.650253238	
72	-977.649966247	
73	-986.816087941	
74	-985.409797023	
75	-896.92186413	
76	-1154.10643951	
77	-1152.42356236	
78	-1700.28857565	
79	-890.804047291	
80	-1157.42970488	
81	-1734.74913532	
82	-1131.25773246	
83	-1144.28052481	
84	-1126.58142511	
85	-876.215618468	
86	-1037.79243049	
87	-1165.27603307	
88	-1243.24254906	
89	-1161.50145899	
90	-892.71385498	
91	-1000.95013979	
92	-932.761378509	
93	-871.90031703	
94	-1179.11131318	
95	-1165.2778248	
96	-1142.58498684	
97	-999.669934307	
98	-1732.72121747	
99	-1176.57019219	
endExperiment		
		
numstates	200	
 num value iterations	30	
 conv type	 circular 	
conv width	11	
 channel_i	1	
 channel_h	50	
 channel_q	15	
hidden layer size	30	
 learning rate	0.0001	
 TAU	0.001	
 batch size	64	
 reward	 	
		
Episodes Spent Training	 10 Episode Eval Avg 	
200	-1274.14687907	
300	-1106.70688081	
400	-839.22065155	
500	-1134.47305455	
600	-782.39969588	
700	-1259.91431072	
800	-978.300680178	
900	-1173.21363883	
Time Training (1000episodes)	4777.64072752	
Evaluation Episode	 Reward 	
0	-1441.93875323	
1	-1148.78662273	
2	-949.045705406	
3	-0.0709728872	
4	-1734.70097477	
5	-1567.37330474	
6	-1368.44700183	
7	-1723.41847582	
8	-837.317806166	
9	-950.511443313	
10	-120.542359137	
11	-0.1414025915	
12	-1286.11096688	
13	-1158.259322	
14	-1026.8127085	
15	-0.7042805209	
16	-1623.76674518	
17	-1251.47452285	
18	-995.011479298	
19	-1090.31267575	
20	-717.341890029	
21	-239.16273006	
22	-1405.97303969	
23	-935.328299615	
24	-1354.03390543	
25	-1733.42555366	
26	-1729.71097054	
27	-121.715681653	
28	-835.052723481	
29	-1599.36578864	
30	-1312.96629903	
31	-1721.03459037	
32	-880.342473834	
33	-1056.09641596	
34	-0.6777204485	
35	-1262.94271407	
36	-936.212145306	
37	-1355.62504818	
38	-120.933553721	
39	-1393.83183978	
40	-1311.13539052	
41	-1120.34176883	
42	-1173.07892845	
43	-944.809334605	
44	-1648.69848569	
45	-947.094545974	
46	-123.125829846	
47	-1689.63428413	
48	-978.715006005	
49	-1293.68401647	
50	-999.105185668	
51	-1266.18320382	
52	-1504.63938281	
53	-1594.40183205	
54	-1047.28874648	
55	-1709.63380061	
56	-1322.59874586	
57	-1381.02788409	
58	-1323.74887466	
59	-1578.2886917	
60	-1441.77683437	
61	-1366.5281684	
62	-1734.34142516	
63	-919.272687967	
64	-958.516306053	
65	-1011.77879943	
66	-117.250394109	
67	-1290.57385147	
68	-993.392314969	
69	-1463.13451682	
70	-0.6223997913	
71	-1274.50628088	
72	-239.535719076	
73	-1645.39614021	
74	-1177.77919459	
75	-1532.77784961	
76	-1269.74342328	
77	-1060.95403689	
78	-1674.54504967	
79	-1178.05458081	
80	-1266.56536798	
81	-914.18183212	
82	-1512.95684574	
83	-1649.52892446	
84	-1068.01629678	
85	-912.642203265	
86	-1275.17261382	
87	-1174.54316407	
88	-0.2391619046	
89	-1733.22359502	
90	-1598.14040966	
91	-1462.91631938	
92	-1471.20476278	
93	-1548.42617203	
94	-1163.93904465	
95	-1719.57290443	
96	-920.968470766	
97	-954.42301247	
98	-1013.85529767	
99	-1032.58538815	
endExperiment		
numstates; 200 
 num value iterations; 30 
 conv type; circular 
conv width; 11 
 channel_i; 1 
 channel_h; 50 
 channel_q; 15 
hidden layer size; 30 
 learning rate; 0.000100 
 TAU; 0.001000 
 batch size; 64 
 reward; 
Episodes Spent Training; 10 Episode Eval Avg 
200; -885.831269334
300; -274.74581613
400; -195.463762544
500; -234.765625386
600; -257.444258362
700; -251.608811412
800; -243.266647917
900; -278.234537249
1000; -233.138895605
1100; -341.907343134
1200; -206.855015985
1300; -243.551774876
1400; -171.496587918
1500; -237.792660276
1600; -247.231032759
1700; -310.405791317
1800; -255.716820275
1900; -356.908354243
2000; -243.91421364
2100; -246.652545625
2200; -260.329435696
2300; -242.843440604
2400; -206.885343752
2500; -304.021419478
2600; -234.221426835
2700; -224.796434941
2800; -351.213556217
2900; -249.041939133
3000; -218.915022536
3100; -273.840014832
3200; -265.61224088
3300; -184.891327451
3400; -265.349139227
3500; -238.159419664
3600; -238.34119214
3700; -218.722031559
3800; -242.610957016
3900; -313.920807164
Time Training (4000episodes);20760.319059848785
Evaluation Episode; Reward 
0; -239.777725451
1; -237.110855557
2; -236.598630299
3; -364.448017763
4; -240.249505322
5; -125.015899508
6; -125.797886002
7; -241.560200247
8; -366.103107538
9; -240.503033173
10; -470.748097025
11; -235.862173845
12; -123.955733325
13; -122.239359735
14; -474.85629606
15; -467.806897618
16; -239.811829664
17; -124.56016046
18; -365.553470745
19; -123.276602899
20; -365.699890366
21; -370.314722263
22; -235.572027854
23; -121.004227937
24; -358.945730327
25; -124.801739394
26; -484.894400851
27; -632.355516922
28; -124.048110346
29; -120.860373772
30; -481.987313823
31; -0.249321888304
32; -365.550175554
33; -125.118362049
34; -121.73616938
35; -237.894027595
36; -120.504974056
37; -362.593705719
38; -493.952936618
39; -234.504877792
40; -124.619282121
41; -371.188121138
42; -0.306833211829
43; -121.859565962
44; -240.703341155
45; -598.988689329
46; -588.791870284
47; -512.066526193
48; -368.835821156
49; -572.295163331
50; -237.413283879
51; -242.043919017
52; -476.246828107
53; -124.065746555
54; -351.780928512
55; -119.0046663
56; -125.455371989
57; -363.509199418
58; -234.550845041
59; -121.871939958
60; -480.604349715
61; -123.008638757
62; -235.789658867
63; -359.84139274
64; -235.489061288
65; -123.281939821
66; -233.9597753
67; -123.899054007
68; -121.093847852
69; -125.155301884
70; -123.681010741
71; -123.670742313
72; -124.084902738
73; -126.344135101
74; -0.226088149118
75; -125.41405328
76; -126.004229057
77; -362.75478466
78; -125.314124472
79; -242.777169577
80; -241.008548036
81; -121.747978186
82; -241.000591829
83; -245.886486762
84; -121.431751813
85; -352.587859171
86; -124.961551442
87; -503.297346164
88; -243.384412933
89; -121.489032251
90; -119.479583363
91; -120.907898148
92; -353.102750219
93; -0.175205315354
94; -483.397945864
95; -364.160080974
96; -241.455250852
97; -122.108578544
98; -122.698394513
99; -352.504176317
endExperiment

numstates; 200 
 num value iterations; 30 
 conv type; circular 
conv width; 11 
 channel_i; 1 
 channel_h; 50 
 channel_q; 15 
hidden layer size; 30 
 learning rate; 0.000100 
 TAU; 0.001000 
 batch size; 64 
 reward; 
Episodes Spent Training; 10 Episode Eval Avg 
200; -800.709281063
300; -976.744813277
400; -816.915328072
500; -339.9358963
600; -416.629513469
700; -365.240175179
800; -367.652306966
900; -159.021044267
Time Training (1000episodes);4568.939696073532
Evaluation Episode; Reward 
0; -124.855523535
1; -121.145455257
2; -126.108536164
3; -246.050805484
4; -241.79662021
5; -237.463916896
6; -246.806619969
7; -359.181272553
8; -240.139614536
9; -500.228929105
10; -122.220814788
11; -124.83495223
12; -125.9444094
13; -123.37535703
14; -0.344022154618
15; -0.252024194621
16; -126.124500911
17; -119.97721887
18; -581.497599754
19; -587.778445494
20; -125.239056558
21; -124.730253565
22; -499.312694278
23; -501.502708862
24; -515.955591168
25; -359.247425041
26; -117.445040082
27; -499.681496466
28; -239.617607606
29; -122.660809364
30; -123.505342877
31; -366.319260339
32; -122.061452645
33; -242.426948588
34; -515.8117273
35; -362.276162042
36; -120.622510952
37; -244.294171197
38; -242.592634301
39; -121.427429532
40; -239.785682341
41; -245.552735102
42; -601.127747465
43; -125.956319993
44; -125.018609287
45; -118.602078398
46; -658.377458521
47; -122.530940812
48; -122.502011234
49; -368.178009444
50; -668.726699247
51; -359.711223404
52; -368.396603488
53; -523.452950615
54; -508.444747666
55; -124.540436924
56; -371.669132482
57; -603.629759351
58; -0.569557269683
59; -371.828617558
60; -125.05792162
61; -125.143531404
62; -636.724121847
63; -649.561935875
64; -120.564070934
65; -565.33554241
66; -124.255158441
67; -488.428680789
68; -245.837459819
69; -120.665709184
70; -122.775111314
71; -247.876614616
72; -495.15417165
73; -365.505444639
74; -122.675746654
75; -123.248338697
76; -245.749527824
77; -509.140275012
78; -486.608123381
79; -465.843360762
80; -124.570655807
81; -244.904249285
82; -240.407632693
83; -240.758488268
84; -125.50514852
85; -125.544698147
86; -1.05419443014
87; -119.122914327
88; -123.551169206
89; -602.416094287
90; -243.064317241
91; -242.998348222
92; -125.600453235
93; -244.319684597
94; -369.526909313
95; -236.799758823
96; -240.119767493
97; -126.17436377
98; -584.147626203
99; -245.85485317
endExperiment

numstates; 200 
 num value iterations; 30 
 conv type; circular 
conv width; 11 
 channel_i; 1 
 channel_h; 50 
 channel_q; 15 
hidden layer size; 50 
 learning rate; 0.000100 
 TAU; 0.001000 
 batch size; 64 
 reward; 
Episodes Spent Training; 10 Episode Eval Avg 
200; -1310.34785942
300; -1441.70805391
400; -1213.50123647
500; -1193.73147489
600; -1179.61205653
700; -811.5417663
800; -984.669924978
900; -1155.38353881
Time Training (1000episodes);5312.244445323944
Evaluation Episode; Reward 
0; -1475.95587645
1; -374.725137289
2; -1401.36685809
3; -858.221285304
4; -1614.60603976
5; -1493.64254659
6; -1070.50462158
7; -1348.22264268
8; -985.509103687
9; -928.536484178
10; -0.617578334243
11; -1.00146392306
12; -1418.04667196
13; -1048.62007669
14; -1463.92213282
15; -1035.81726335
16; -1694.42969974
17; -748.213891073
18; -126.078766332
19; -124.715011417
20; -1161.5496752
21; -748.699669662
22; -1.35827054138
23; -0.873424265963
24; -126.166936485
25; -755.658230699
26; -873.25693048
27; -983.531121037
28; -994.651373033
29; -1584.69384067
30; -985.897573666
31; -882.368456557
32; -1193.94596647
33; -1732.32576884
34; -1206.09888835
35; -1567.57690302
36; -1061.48975485
37; -987.06100154
38; -126.516413697
39; -249.450930494
40; -1048.21431874
41; -1730.7536353
42; -1730.04849986
43; -1444.82446702
44; -1118.72041743
45; -1014.39908565
46; -1683.03202455
47; -870.147805908
48; -1437.83705912
49; -1460.41794604
50; -1105.645187
51; -1052.64809684
52; -1482.88356198
53; -1103.07799813
54; -1346.62427967
55; -1229.35551577
56; -1096.57312703
57; -1474.9326542
58; -1436.10060278
59; -1012.8903586
60; -1729.27675807
61; -1670.35142691
62; -1355.46589849
63; -1733.28396141
64; -1038.73375753
65; -1099.11737353
66; -1317.39778764
67; -1450.72281623
68; -1508.57258217
69; -1532.79374575
70; -125.387863173
71; -1253.22436296
72; -986.718937118
73; -1406.89136202
74; -1117.03076706
75; -1301.39925322
76; -1069.37142103
77; -1227.66379762
78; -873.779419131
79; -1125.25692858
80; -744.879652289
81; -1460.65753533
82; -126.495412975
83; -1404.31399422
84; -1372.51752766
85; -1319.50138362
86; -1237.30970418
87; -1134.31432517
88; -1033.6053118
89; -1379.56143904
90; -974.202371061
91; -1365.42366681
92; -1071.90771459
93; -124.63410749
94; -1224.57746836
95; -1488.49335165
96; -1.11996111219
97; -1052.04625466
98; -1401.59637196
99; -0.673406899265
endExperiment

numstates; 200 
 num value iterations; 30 
 conv type; circular 
conv width; 11 
 channel_i; 1 
 channel_h; 50 
 channel_q; 15 
hidden layer size; 50 
 learning rate; 0.000100 
 TAU; 0.001000 
 batch size; 64 
 reward; 
 New angle formula 
Episodes Spent Training; 10 Episode Eval Avg 
200; -970.948876108
300; -603.571716131
400; -445.197967001
500; -392.725815896
600; -212.574430204
700; -425.950137156
800; -173.37196666
900; -436.039733418
Time Training (1000episodes);4863.61545419693
Evaluation Episode; Reward 
0; -492.744437167
1; -248.808492002
2; -246.282947715
3; -607.246731092
4; -127.740062714
5; -127.633384322
6; -249.407455168
7; -127.785698533
8; -249.358697668
9; -0.605214698359
10; -126.76262844
11; -127.744603973
12; -623.726188907
13; -125.297514635
14; -0.254283105357
15; -369.265886513
16; -620.970706561
17; -124.99862978
18; -501.644456972
19; -119.394073169
20; -906.316867691
21; -0.247866092178
22; -252.458689064
23; -358.66852832
24; -126.047366246
25; -246.970100908
26; -243.224999416
27; -813.705812601
28; -619.054263036
29; -124.709758569
30; -758.018504131
31; -252.218818355
32; -368.606146958
33; -630.217703811
34; -369.121368255
35; -994.492034552
36; -776.834753422
37; -781.857805161
38; -502.602236857
39; -610.374297892
40; -127.792766911
41; -121.259427777
42; -126.434270913
43; -613.331653569
44; -617.354929447
45; -124.981504374
46; -0.430043056821
47; -121.419063314
48; -494.755362278
49; -247.778198503
50; -0.623825845281
51; -249.786550887
52; -125.567964156
53; -246.785054415
54; -125.214379201
55; -627.283986149
56; -125.845479862
57; -245.910723699
58; -368.756546252
59; -358.547153217
60; -246.940779864
61; -619.873840059
62; -243.489100423
63; -127.06665728
64; -124.413097289
65; -0.271299154404
66; -609.384290825
67; -124.210364265
68; -899.121034477
69; -766.886850103
70; -124.886075657
71; -498.916890376
72; -124.160540153
73; -248.020951891
74; -373.610300904
75; -367.616717414
76; -492.621714926
77; -369.143792892
78; -491.465209809
79; -0.243039928035
80; -123.01497057
81; -248.029289946
82; -488.065685689
83; -245.996987125
84; -0.30179219473
85; -755.510531523
86; -250.903725479
87; -489.308171457
88; -663.846125593
89; -127.310114234
90; -620.511552969
91; -607.467354659
92; -789.106241469
93; -369.175683381
94; -494.261442612
95; -366.327302309
96; -497.644301068
97; -250.574559801
98; -122.116778914
99; -628.939104546
endExperiment

numstates; 100 
 num value iterations; 30 
 conv type; circular 
conv width; 7 
 channel_i; 1 
 channel_h; 50 
 channel_q; 15 
hidden layer size; 30 
 learning rate; 0.000100 
 TAU; 0.001000 
 batch size; 64 
 reward; 
 New angle formula 
Episodes Spent Training; 10 Episode Eval Avg 
200; -755.786229886
300; -660.134687613
400; -515.726328499
500; -431.435994474
600; -510.65272166
700; -504.098367796
800; -391.824995722
900; -462.810561608
Time Training (1000episodes);4923.683123826981
Evaluation Episode; Reward 
0; -618.487203993
1; -237.226949124
2; -124.660099215
3; -124.471436111
4; -362.855117654
5; -494.802296926
6; -127.60465581
7; -124.707481937
8; -0.342190056169
9; -359.100898726
10; -254.518783051
11; -122.971681757
12; -589.346912717
13; -238.52366344
14; -125.245718321
15; -122.521904738
16; -124.887115173
17; -238.24504545
18; -125.802441868
19; -235.348031758
20; -126.92878447
21; -123.528196177
22; -357.284185436
23; -528.337004606
24; -125.177710819
25; -117.552074004
26; -121.703826874
27; -123.804485457
28; -770.002260557
29; -0.485501991286
30; -124.849355598
31; -498.113022227
32; -123.792655766
33; -367.159381027
34; -239.589195128
35; -124.242429659
36; -242.956352557
37; -126.305168556
38; -644.209579082
39; -492.384964528
40; -242.828341522
41; -477.076279167
42; -481.658081306
43; -606.240360566
44; -244.939050461
45; -243.400650664
46; -601.635387904
47; -125.790950638
48; -373.376820694
49; -768.894904968
50; -238.355189631
51; -366.700751058
52; -366.530694668
53; -234.675916775
54; -122.415290634
55; -883.670112814
56; -125.687636661
57; -610.540056979
58; -362.315520765
59; -122.477096676
60; -543.829633721
61; -123.016774097
62; -360.316889708
63; -515.615808441
64; -123.964522185
65; -0.420563057989
66; -515.371977009
67; -0.395543443188
68; -242.27720064
69; -475.458817166
70; -250.737155099
71; -119.780515998
72; -605.806030197
73; -243.20435308
74; -125.321506926
75; -362.594744689
76; -367.752070127
77; -492.176645651
78; -356.759854691
79; -489.045260878
80; -126.761327541
81; -507.594382569
82; -366.865773826
83; -368.504928648
84; -0.718944439824
85; -766.6629069
86; -352.437306525
87; -497.088313842
88; -247.79760783
89; -239.668127814
90; -124.028574945
91; -0.377287863581
92; -0.445721834533
93; -371.722481117
94; -351.692271311
95; -126.45199776
96; -352.392305159
97; -124.319313021
98; -244.501499144
99; -124.855228119
endExperiment

numstates; 10 
 num value iterations; 30 
 conv type; circular 
conv width; 7 
 channel_i; 1 
 channel_h; 50 
 channel_q; 15 
hidden layer size; 30 
 learning rate; 0.000100 
 TAU; 0.001000 
 batch size; 64 
 reward; 
 New angle formula 
Episodes Spent Training; 10 Episode Eval Avg 
200; -1177.36042652
300; -1390.27404245
400; -959.238290203
500; -913.814823977
600; -832.647774774
700; -816.841112899
800; -780.315314354
900; -645.050960926
Time Training (1000episodes);4875.965358257294
Evaluation Episode; Reward 
0; -1012.11823774
1; -1484.46422439
2; -855.126204686
3; -1439.18177129
4; -367.56909746
5; -1699.45818849
6; -1232.59832666
7; -1581.7233981
8; -1592.46987105
9; -125.639770222
10; -738.21998488
11; -1620.55496593
12; -609.092131059
13; -1718.93467422
14; -367.428005727
15; -126.755782653
16; -125.625578481
17; -1700.48258392
18; -362.382353745
19; -1203.75267685
20; -1494.96201597
21; -366.460662274
22; -988.602099072
23; -244.632243233
24; -1733.24988154
25; -1451.39319396
26; -119.036683204
27; -1306.74788501
28; -124.076284783
29; -1608.55210561
30; -1359.99104398
31; -125.368079751
32; -493.946131224
33; -249.153467315
34; -0.232347190816
35; -245.584544872
36; -359.519794577
37; -0.474003082025
38; -248.493764732
39; -249.129685521
40; -124.39299511
41; -1495.92553495
42; -1573.99850143
43; -612.820732449
44; -124.602476411
45; -365.760409286
46; -1459.65874618
47; -1228.51418636
48; -0.375541815184
49; -1625.44911066
50; -242.053818796
51; -734.76160842
52; -244.921531309
53; -1522.57602693
54; -364.940335519
55; -1563.15923834
56; -120.967098942
57; -126.550592331
58; -861.797595475
59; -0.230618152802
60; -359.900151389
61; -369.498531617
62; -246.831317637
63; -1651.13988645
64; -1126.27607858
65; -1628.02161432
66; -610.49803271
67; -0.359079024334
68; -1396.20588202
69; -1737.19117252
70; -490.353333766
71; -854.003730889
72; -244.969692405
73; -1312.20092032
74; -0.478003495035
75; -1732.90074273
76; -125.415103672
77; -1735.32898799
78; -126.969651273
79; -990.706541788
80; -1117.25395409
81; -1265.25607865
82; -369.804648353
83; -986.051022355
84; -1220.31603569
85; -246.026057014
86; -0.216723393809
87; -1680.36123605
88; -609.282232071
89; -122.370591247
90; -125.712734499
91; -365.507382495
92; -1690.43487353
93; -247.631530432
94; -1243.93321982
95; -0.378869958357
96; -489.203641292
97; -1738.21774601
98; -125.173551399
99; -1574.05331197
endExperiment

